{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import * \n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "train_path= '/Users/wwang/Desktop/work/ultrasound breast classification/train'\n",
    "test_path='/Users/wwang/Desktop/work/ultrasound breast classification/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wwang/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - AUC: 0.6785 - Precision: 0.5993 - Recall: 0.5833 - accuracy: 0.6226 - loss: 0.8008\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67444, saving model to model_224_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - AUC: 0.6799 - Precision: 0.6013 - Recall: 0.5838 - accuracy: 0.6236 - loss: 0.8028 - val_AUC: 0.7630 - val_Precision: 0.6085 - val_Recall: 0.7500 - val_accuracy: 0.6744 - val_loss: 0.5890\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - AUC: 0.7319 - Precision: 0.5568 - Recall: 0.6649 - accuracy: 0.6210 - loss: 0.8926\n",
      "Epoch 2: val_accuracy improved from 0.67444 to 0.70556, saving model to model_224_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - AUC: 0.7303 - Precision: 0.5597 - Recall: 0.6625 - accuracy: 0.6212 - loss: 0.8940 - val_AUC: 0.7684 - val_Precision: 0.6934 - val_Recall: 0.6050 - val_accuracy: 0.7056 - val_loss: 0.5798\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - AUC: 0.7114 - Precision: 0.5949 - Recall: 0.6352 - accuracy: 0.6588 - loss: 0.6807\n",
      "Epoch 3: val_accuracy improved from 0.70556 to 0.74000, saving model to model_224_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - AUC: 0.7130 - Precision: 0.5955 - Recall: 0.6377 - accuracy: 0.6591 - loss: 0.6813 - val_AUC: 0.8409 - val_Precision: 0.8120 - val_Recall: 0.5400 - val_accuracy: 0.7400 - val_loss: 0.5092\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - AUC: 0.7243 - Precision: 0.7469 - Recall: 0.6881 - accuracy: 0.7114 - loss: 0.7707\n",
      "Epoch 4: val_accuracy did not improve from 0.74000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - AUC: 0.7251 - Precision: 0.7448 - Recall: 0.6878 - accuracy: 0.7109 - loss: 0.7683 - val_AUC: 0.8179 - val_Precision: 0.7096 - val_Recall: 0.6475 - val_accuracy: 0.7256 - val_loss: 0.5144\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - AUC: 0.7894 - Precision: 0.6433 - Recall: 0.6798 - accuracy: 0.6807 - loss: 0.6504\n",
      "Epoch 5: val_accuracy improved from 0.74000 to 0.77222, saving model to model_224_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - AUC: 0.7889 - Precision: 0.6452 - Recall: 0.6802 - accuracy: 0.6818 - loss: 0.6501 - val_AUC: 0.8463 - val_Precision: 0.7407 - val_Recall: 0.7500 - val_accuracy: 0.7722 - val_loss: 0.4798\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - AUC: 0.7513 - Precision: 0.7253 - Recall: 0.6746 - accuracy: 0.6529 - loss: 0.6371\n",
      "Epoch 6: val_accuracy did not improve from 0.77222\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - AUC: 0.7512 - Precision: 0.7249 - Recall: 0.6753 - accuracy: 0.6535 - loss: 0.6385 - val_AUC: 0.8377 - val_Precision: 0.8061 - val_Recall: 0.5925 - val_accuracy: 0.7556 - val_loss: 0.5271\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - AUC: 0.6949 - Precision: 0.6818 - Recall: 0.5591 - accuracy: 0.6035 - loss: 0.7412\n",
      "Epoch 7: val_accuracy did not improve from 0.77222\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 997ms/step - AUC: 0.6954 - Precision: 0.6801 - Recall: 0.5618 - accuracy: 0.6048 - loss: 0.7396 - val_AUC: 0.8412 - val_Precision: 0.6809 - val_Recall: 0.8000 - val_accuracy: 0.7444 - val_loss: 0.5012\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - AUC: 0.8840 - Precision: 0.7820 - Recall: 0.8206 - accuracy: 0.8037 - loss: 0.4380\n",
      "Epoch 8: val_accuracy did not improve from 0.77222\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - AUC: 0.8802 - Precision: 0.7788 - Recall: 0.8171 - accuracy: 0.8007 - loss: 0.4430 - val_AUC: 0.8557 - val_Precision: 0.7073 - val_Recall: 0.8275 - val_accuracy: 0.7711 - val_loss: 0.4934\n",
      "Total time taken for model model_224: 199.10 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 95ms/step - AUC: 0.8712 - Precision: 0.7093 - Recall: 0.8325 - accuracy: 0.7843 - loss: 0.4613\n",
      "Evaluation results for model_224:\n",
      "Loss: 0.46797484159469604, Accuracy: 0.7711111307144165, AUC: 0.8690850734710693, Precision: 0.7081544995307922, Recall: 0.824999988079071\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - AUC: 0.5468 - Precision: 0.5005 - Recall: 0.5238 - accuracy: 0.5355 - loss: 0.9078\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59111, saving model to model_128_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 604ms/step - AUC: 0.5553 - Precision: 0.5059 - Recall: 0.5245 - accuracy: 0.5385 - loss: 0.9027 - val_AUC: 0.6405 - val_Precision: 0.6538 - val_Recall: 0.1700 - val_accuracy: 0.5911 - val_loss: 0.7973\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - AUC: 0.7008 - Precision: 0.6104 - Recall: 0.7137 - accuracy: 0.6474 - loss: 0.8251\n",
      "Epoch 2: val_accuracy improved from 0.59111 to 0.71000, saving model to model_128_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 533ms/step - AUC: 0.7017 - Precision: 0.6083 - Recall: 0.7135 - accuracy: 0.6469 - loss: 0.8247 - val_AUC: 0.7681 - val_Precision: 0.7683 - val_Recall: 0.4975 - val_accuracy: 0.7100 - val_loss: 0.6060\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - AUC: 0.7205 - Precision: 0.6316 - Recall: 0.5001 - accuracy: 0.6007 - loss: 1.0624\n",
      "Epoch 3: val_accuracy did not improve from 0.71000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 504ms/step - AUC: 0.7213 - Precision: 0.6361 - Recall: 0.5043 - accuracy: 0.6033 - loss: 1.0560 - val_AUC: 0.7759 - val_Precision: 0.6751 - val_Recall: 0.6650 - val_accuracy: 0.7089 - val_loss: 0.5805\n",
      "Epoch 4/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - AUC: 0.7496 - Precision: 0.7048 - Recall: 0.7355 - accuracy: 0.7161 - loss: 0.6974\n",
      "Epoch 4: val_accuracy improved from 0.71000 to 0.74000, saving model to model_128_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 515ms/step - AUC: 0.7473 - Precision: 0.7046 - Recall: 0.7275 - accuracy: 0.7113 - loss: 0.7062 - val_AUC: 0.8332 - val_Precision: 0.6912 - val_Recall: 0.7500 - val_accuracy: 0.7400 - val_loss: 0.5042\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - AUC: 0.7800 - Precision: 0.6539 - Recall: 0.7220 - accuracy: 0.6842 - loss: 0.6495\n",
      "Epoch 5: val_accuracy improved from 0.74000 to 0.77333, saving model to model_128_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 537ms/step - AUC: 0.7760 - Precision: 0.6500 - Recall: 0.7210 - accuracy: 0.6814 - loss: 0.6572 - val_AUC: 0.8746 - val_Precision: 0.6849 - val_Recall: 0.9075 - val_accuracy: 0.7733 - val_loss: 0.4878\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - AUC: 0.8144 - Precision: 0.8132 - Recall: 0.7047 - accuracy: 0.7222 - loss: 0.5468\n",
      "Epoch 6: val_accuracy did not improve from 0.77333\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 517ms/step - AUC: 0.8163 - Precision: 0.8148 - Recall: 0.7053 - accuracy: 0.7238 - loss: 0.5446 - val_AUC: 0.8527 - val_Precision: 0.6948 - val_Recall: 0.8425 - val_accuracy: 0.7656 - val_loss: 0.5028\n",
      "Epoch 7/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - AUC: 0.7847 - Precision: 0.6900 - Recall: 0.6521 - accuracy: 0.7073 - loss: 0.6459\n",
      "Epoch 7: val_accuracy improved from 0.77333 to 0.79556, saving model to model_128_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 522ms/step - AUC: 0.7890 - Precision: 0.6939 - Recall: 0.6539 - accuracy: 0.7091 - loss: 0.6365 - val_AUC: 0.8776 - val_Precision: 0.7609 - val_Recall: 0.7875 - val_accuracy: 0.7956 - val_loss: 0.4440\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - AUC: 0.7174 - Precision: 0.7135 - Recall: 0.6999 - accuracy: 0.6549 - loss: 0.7350\n",
      "Epoch 8: val_accuracy did not improve from 0.79556\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 516ms/step - AUC: 0.7183 - Precision: 0.7136 - Recall: 0.6989 - accuracy: 0.6558 - loss: 0.7339 - val_AUC: 0.8857 - val_Precision: 0.8171 - val_Recall: 0.6700 - val_accuracy: 0.7867 - val_loss: 0.4418\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - AUC: 0.8851 - Precision: 0.8405 - Recall: 0.7516 - accuracy: 0.7635 - loss: 0.4641\n",
      "Epoch 9: val_accuracy did not improve from 0.79556\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 518ms/step - AUC: 0.8823 - Precision: 0.8369 - Recall: 0.7509 - accuracy: 0.7617 - loss: 0.4684 - val_AUC: 0.8644 - val_Precision: 0.8301 - val_Recall: 0.6475 - val_accuracy: 0.7844 - val_loss: 0.4901\n",
      "Epoch 10/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - AUC: 0.7825 - Precision: 0.5520 - Recall: 0.8773 - accuracy: 0.6729 - loss: 0.6135\n",
      "Epoch 10: val_accuracy did not improve from 0.79556\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 535ms/step - AUC: 0.7860 - Precision: 0.5607 - Recall: 0.8754 - accuracy: 0.6790 - loss: 0.6098 - val_AUC: 0.8048 - val_Precision: 0.7574 - val_Recall: 0.5775 - val_accuracy: 0.7300 - val_loss: 0.6120\n",
      "Total time taken for model model_128: 130.20 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - AUC: 0.8177 - Precision: 0.8260 - Recall: 0.6099 - accuracy: 0.7601 - loss: 0.6054\n",
      "Evaluation results for model_128:\n",
      "Loss: 0.5734663009643555, Accuracy: 0.7611111402511597, AUC: 0.8240974545478821, Precision: 0.7974276542663574, Recall: 0.6200000047683716\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - AUC: 0.3932 - Precision: 0.5612 - Recall: 0.5375 - accuracy: 0.5057 - loss: 1.0692\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46667, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 347ms/step - AUC: 0.3987 - Precision: 0.5604 - Recall: 0.5395 - accuracy: 0.5080 - loss: 1.0685 - val_AUC: 0.6404 - val_Precision: 0.4523 - val_Recall: 0.9475 - val_accuracy: 0.4667 - val_loss: 0.7866\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - AUC: 0.5447 - Precision: 0.5664 - Recall: 0.5233 - accuracy: 0.5064 - loss: 0.9489\n",
      "Epoch 2: val_accuracy improved from 0.46667 to 0.50778, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - AUC: 0.5436 - Precision: 0.5657 - Recall: 0.5235 - accuracy: 0.5069 - loss: 0.9476 - val_AUC: 0.6213 - val_Precision: 0.4725 - val_Recall: 0.9225 - val_accuracy: 0.5078 - val_loss: 0.7837\n",
      "Epoch 3/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - AUC: 0.6452 - Precision: 0.6296 - Recall: 0.6264 - accuracy: 0.6174 - loss: 0.8106\n",
      "Epoch 3: val_accuracy did not improve from 0.50778\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - AUC: 0.6453 - Precision: 0.6314 - Recall: 0.6256 - accuracy: 0.6172 - loss: 0.8083 - val_AUC: 0.6426 - val_Precision: 0.4525 - val_Recall: 0.9525 - val_accuracy: 0.4667 - val_loss: 0.8955\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - AUC: 0.4866 - Precision: 0.5558 - Recall: 0.5520 - accuracy: 0.5095 - loss: 0.8555\n",
      "Epoch 4: val_accuracy improved from 0.50778 to 0.51333, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - AUC: 0.4882 - Precision: 0.5562 - Recall: 0.5534 - accuracy: 0.5108 - loss: 0.8559 - val_AUC: 0.6613 - val_Precision: 0.4767 - val_Recall: 0.9700 - val_accuracy: 0.5133 - val_loss: 0.8352\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - AUC: 0.6738 - Precision: 0.6200 - Recall: 0.6324 - accuracy: 0.6393 - loss: 0.7001\n",
      "Epoch 5: val_accuracy improved from 0.51333 to 0.58444, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - AUC: 0.6735 - Precision: 0.6195 - Recall: 0.6314 - accuracy: 0.6387 - loss: 0.7001 - val_AUC: 0.7474 - val_Precision: 0.5196 - val_Recall: 0.8625 - val_accuracy: 0.5844 - val_loss: 0.6895\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - AUC: 0.6387 - Precision: 0.5791 - Recall: 0.6118 - accuracy: 0.5496 - loss: 0.7677\n",
      "Epoch 6: val_accuracy improved from 0.58444 to 0.64333, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - AUC: 0.6390 - Precision: 0.5805 - Recall: 0.6130 - accuracy: 0.5517 - loss: 0.7660 - val_AUC: 0.7066 - val_Precision: 0.5853 - val_Recall: 0.6775 - val_accuracy: 0.6433 - val_loss: 0.6309\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - AUC: 0.7278 - Precision: 0.6464 - Recall: 0.7000 - accuracy: 0.6889 - loss: 0.6562\n",
      "Epoch 7: val_accuracy improved from 0.64333 to 0.65000, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - AUC: 0.7254 - Precision: 0.6463 - Recall: 0.6979 - accuracy: 0.6872 - loss: 0.6592 - val_AUC: 0.7239 - val_Precision: 0.6693 - val_Recall: 0.4200 - val_accuracy: 0.6500 - val_loss: 0.6328\n",
      "Epoch 8/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - AUC: 0.7795 - Precision: 0.7143 - Recall: 0.8047 - accuracy: 0.7429 - loss: 0.5764\n",
      "Epoch 8: val_accuracy improved from 0.65000 to 0.71778, saving model to model_64_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - AUC: 0.7792 - Precision: 0.7105 - Recall: 0.8021 - accuracy: 0.7409 - loss: 0.5772 - val_AUC: 0.7697 - val_Precision: 0.7017 - val_Recall: 0.6350 - val_accuracy: 0.7178 - val_loss: 0.5695\n",
      "Epoch 9/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - AUC: 0.7124 - Precision: 0.5187 - Recall: 0.6457 - accuracy: 0.6418 - loss: 0.6263\n",
      "Epoch 9: val_accuracy did not improve from 0.71778\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 281ms/step - AUC: 0.7132 - Precision: 0.5190 - Recall: 0.6438 - accuracy: 0.6413 - loss: 0.6251 - val_AUC: 0.7182 - val_Precision: 0.6901 - val_Recall: 0.4900 - val_accuracy: 0.6756 - val_loss: 0.6258\n",
      "Epoch 10/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - AUC: 0.8663 - Precision: 0.8334 - Recall: 0.6776 - accuracy: 0.7405 - loss: 0.4630\n",
      "Epoch 10: val_accuracy did not improve from 0.71778\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - AUC: 0.8620 - Precision: 0.8253 - Recall: 0.6744 - accuracy: 0.7379 - loss: 0.4687 - val_AUC: 0.7397 - val_Precision: 0.7309 - val_Recall: 0.4550 - val_accuracy: 0.6833 - val_loss: 0.6370\n",
      "Total time taken for model model_64: 74.69 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - AUC: 0.7535 - Precision: 0.7042 - Recall: 0.4715 - accuracy: 0.6647 - loss: 0.6239\n",
      "Evaluation results for model_64:\n",
      "Loss: 0.6094428300857544, Accuracy: 0.6800000071525574, AUC: 0.762332558631897, Precision: 0.7153846025466919, Recall: 0.4650000035762787\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - AUC: 0.6230 - Precision: 0.5121 - Recall: 0.5541 - accuracy: 0.5518 - loss: 0.8198\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69889, saving model to model_243_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - AUC: 0.6229 - Precision: 0.5154 - Recall: 0.5543 - accuracy: 0.5526 - loss: 0.8241 - val_AUC: 0.7903 - val_Precision: 0.7009 - val_Recall: 0.5625 - val_accuracy: 0.6989 - val_loss: 0.5578\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - AUC: 0.6323 - Precision: 0.7131 - Recall: 0.6063 - accuracy: 0.6192 - loss: 0.8752\n",
      "Epoch 2: val_accuracy did not improve from 0.69889\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - AUC: 0.6347 - Precision: 0.7121 - Recall: 0.6075 - accuracy: 0.6203 - loss: 0.8705 - val_AUC: 0.8007 - val_Precision: 0.5842 - val_Recall: 0.8675 - val_accuracy: 0.6667 - val_loss: 0.6033\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - AUC: 0.8301 - Precision: 0.7243 - Recall: 0.7771 - accuracy: 0.7557 - loss: 0.5617\n",
      "Epoch 3: val_accuracy improved from 0.69889 to 0.70556, saving model to model_243_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - AUC: 0.8291 - Precision: 0.7234 - Recall: 0.7760 - accuracy: 0.7550 - loss: 0.5628 - val_AUC: 0.8090 - val_Precision: 0.6321 - val_Recall: 0.8075 - val_accuracy: 0.7056 - val_loss: 0.5583\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - AUC: 0.7092 - Precision: 0.4921 - Recall: 0.6109 - accuracy: 0.6009 - loss: 0.8107\n",
      "Epoch 4: val_accuracy improved from 0.70556 to 0.73778, saving model to model_243_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - AUC: 0.7096 - Precision: 0.4920 - Recall: 0.6120 - accuracy: 0.6015 - loss: 0.8092 - val_AUC: 0.8401 - val_Precision: 0.8333 - val_Recall: 0.5125 - val_accuracy: 0.7378 - val_loss: 0.5319\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - AUC: 0.8591 - Precision: 0.7745 - Recall: 0.6292 - accuracy: 0.6935 - loss: 0.5002\n",
      "Epoch 5: val_accuracy improved from 0.73778 to 0.75222, saving model to model_243_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - AUC: 0.8592 - Precision: 0.7752 - Recall: 0.6302 - accuracy: 0.6945 - loss: 0.4993 - val_AUC: 0.8471 - val_Precision: 0.8554 - val_Recall: 0.5325 - val_accuracy: 0.7522 - val_loss: 0.5311\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - AUC: 0.8833 - Precision: 0.7841 - Recall: 0.7888 - accuracy: 0.8013 - loss: 0.4559\n",
      "Epoch 6: val_accuracy improved from 0.75222 to 0.77444, saving model to model_243_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - AUC: 0.8824 - Precision: 0.7791 - Recall: 0.7878 - accuracy: 0.7993 - loss: 0.4567 - val_AUC: 0.8594 - val_Precision: 0.7641 - val_Recall: 0.7125 - val_accuracy: 0.7744 - val_loss: 0.4686\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - AUC: 0.6804 - Precision: 0.5605 - Recall: 0.6738 - accuracy: 0.6256 - loss: 0.7670\n",
      "Epoch 7: val_accuracy improved from 0.77444 to 0.80333, saving model to model_243_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - AUC: 0.6801 - Precision: 0.5615 - Recall: 0.6698 - accuracy: 0.6244 - loss: 0.7669 - val_AUC: 0.8839 - val_Precision: 0.7700 - val_Recall: 0.7950 - val_accuracy: 0.8033 - val_loss: 0.4235\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - AUC: 0.8335 - Precision: 0.8257 - Recall: 0.8023 - accuracy: 0.8105 - loss: 0.5942\n",
      "Epoch 8: val_accuracy did not improve from 0.80333\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - AUC: 0.8315 - Precision: 0.8227 - Recall: 0.8002 - accuracy: 0.8080 - loss: 0.5971 - val_AUC: 0.8378 - val_Precision: 0.6647 - val_Recall: 0.8275 - val_accuracy: 0.7378 - val_loss: 0.5305\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - AUC: 0.7529 - Precision: 0.6534 - Recall: 0.5626 - accuracy: 0.6621 - loss: 0.6347\n",
      "Epoch 9: val_accuracy did not improve from 0.80333\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - AUC: 0.7546 - Precision: 0.6573 - Recall: 0.5684 - accuracy: 0.6644 - loss: 0.6319 - val_AUC: 0.8665 - val_Precision: 0.6719 - val_Recall: 0.8500 - val_accuracy: 0.7489 - val_loss: 0.5097\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - AUC: 0.8151 - Precision: 0.5389 - Recall: 0.7768 - accuracy: 0.6713 - loss: 0.5958\n",
      "Epoch 10: val_accuracy did not improve from 0.80333\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - AUC: 0.8128 - Precision: 0.5419 - Recall: 0.7708 - accuracy: 0.6707 - loss: 0.5967 - val_AUC: 0.8717 - val_Precision: 0.7394 - val_Recall: 0.7875 - val_accuracy: 0.7822 - val_loss: 0.4486\n",
      "Total time taken for model model_243: 283.38 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - AUC: 0.8643 - Precision: 0.7096 - Recall: 0.7529 - accuracy: 0.7574 - loss: 0.4491\n",
      "Evaluation results for model_243:\n",
      "Loss: 0.46706056594848633, Accuracy: 0.7588889002799988, AUC: 0.8581799864768982, Precision: 0.7152941226959229, Recall: 0.7599999904632568\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - AUC: 0.5596 - Precision: 0.3937 - Recall: 0.4321 - accuracy: 0.5274 - loss: 1.0194\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60222, saving model to model_162_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 858ms/step - AUC: 0.5604 - Precision: 0.3943 - Recall: 0.4349 - accuracy: 0.5280 - loss: 1.0199 - val_AUC: 0.6997 - val_Precision: 0.6694 - val_Recall: 0.2075 - val_accuracy: 0.6022 - val_loss: 0.6512\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - AUC: 0.7369 - Precision: 0.6875 - Recall: 0.5892 - accuracy: 0.6946 - loss: 0.6294\n",
      "Epoch 2: val_accuracy improved from 0.60222 to 0.73778, saving model to model_162_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 694ms/step - AUC: 0.7333 - Precision: 0.6859 - Recall: 0.5853 - accuracy: 0.6910 - loss: 0.6364 - val_AUC: 0.8417 - val_Precision: 0.7628 - val_Recall: 0.5950 - val_accuracy: 0.7378 - val_loss: 0.5093\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - AUC: 0.7453 - Precision: 0.7521 - Recall: 0.6272 - accuracy: 0.6533 - loss: 0.7250\n",
      "Epoch 3: val_accuracy did not improve from 0.73778\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 670ms/step - AUC: 0.7454 - Precision: 0.7547 - Recall: 0.6284 - accuracy: 0.6546 - loss: 0.7242 - val_AUC: 0.7610 - val_Precision: 0.6634 - val_Recall: 0.6700 - val_accuracy: 0.7022 - val_loss: 0.5807\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - AUC: 0.7847 - Precision: 0.5662 - Recall: 0.7953 - accuracy: 0.6750 - loss: 0.5816\n",
      "Epoch 4: val_accuracy did not improve from 0.73778\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 677ms/step - AUC: 0.7852 - Precision: 0.5668 - Recall: 0.7957 - accuracy: 0.6763 - loss: 0.5825 - val_AUC: 0.7562 - val_Precision: 0.6794 - val_Recall: 0.5350 - val_accuracy: 0.6811 - val_loss: 0.5910\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - AUC: 0.6500 - Precision: 0.6966 - Recall: 0.5807 - accuracy: 0.5945 - loss: 0.8649\n",
      "Epoch 5: val_accuracy did not improve from 0.73778\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 686ms/step - AUC: 0.6509 - Precision: 0.6959 - Recall: 0.5811 - accuracy: 0.5953 - loss: 0.8633 - val_AUC: 0.8131 - val_Precision: 0.8077 - val_Recall: 0.5250 - val_accuracy: 0.7333 - val_loss: 0.5440\n",
      "Total time taken for model model_162: 89.30 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - AUC: 0.7900 - Precision: 0.7691 - Recall: 0.4955 - accuracy: 0.7100 - loss: 0.5685\n",
      "Evaluation results for model_162:\n",
      "Loss: 0.5576960444450378, Accuracy: 0.7222222089767456, AUC: 0.8046249747276306, Precision: 0.7952755689620972, Recall: 0.5049999952316284\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - AUC: 0.6334 - Precision: 0.7910 - Recall: 0.5135 - accuracy: 0.6082 - loss: 1.0105\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60667, saving model to model_81_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 422ms/step - AUC: 0.6352 - Precision: 0.7882 - Recall: 0.5159 - accuracy: 0.6093 - loss: 1.0042 - val_AUC: 0.6846 - val_Precision: 0.5447 - val_Recall: 0.7000 - val_accuracy: 0.6067 - val_loss: 0.6731\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.6983 - Precision: 0.5568 - Recall: 0.7432 - accuracy: 0.6222 - loss: 0.8262\n",
      "Epoch 2: val_accuracy did not improve from 0.60667\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - AUC: 0.6975 - Precision: 0.5560 - Recall: 0.7411 - accuracy: 0.6214 - loss: 0.8272 - val_AUC: 0.7162 - val_Precision: 0.5362 - val_Recall: 0.7600 - val_accuracy: 0.6011 - val_loss: 0.6627\n",
      "Epoch 3/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - AUC: 0.5532 - Precision: 0.6115 - Recall: 0.4289 - accuracy: 0.5089 - loss: 0.9159\n",
      "Epoch 3: val_accuracy improved from 0.60667 to 0.62222, saving model to model_81_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - AUC: 0.5591 - Precision: 0.6178 - Recall: 0.4375 - accuracy: 0.5166 - loss: 0.9095 - val_AUC: 0.7252 - val_Precision: 0.5562 - val_Recall: 0.7425 - val_accuracy: 0.6222 - val_loss: 0.6425\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - AUC: 0.6227 - Precision: 0.4594 - Recall: 0.5913 - accuracy: 0.5508 - loss: 0.8180\n",
      "Epoch 4: val_accuracy improved from 0.62222 to 0.69333, saving model to model_81_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - AUC: 0.6237 - Precision: 0.4606 - Recall: 0.5925 - accuracy: 0.5529 - loss: 0.8171 - val_AUC: 0.7863 - val_Precision: 0.7672 - val_Recall: 0.4450 - val_accuracy: 0.6933 - val_loss: 0.5859\n",
      "Epoch 5/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.6650 - Precision: 0.6902 - Recall: 0.5810 - accuracy: 0.6199 - loss: 0.7335\n",
      "Epoch 5: val_accuracy improved from 0.69333 to 0.70889, saving model to model_81_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - AUC: 0.6687 - Precision: 0.6946 - Recall: 0.5845 - accuracy: 0.6228 - loss: 0.7325 - val_AUC: 0.7509 - val_Precision: 0.7041 - val_Recall: 0.5950 - val_accuracy: 0.7089 - val_loss: 0.5884\n",
      "Epoch 6/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.6616 - Precision: 0.6589 - Recall: 0.6608 - accuracy: 0.6669 - loss: 0.7673\n",
      "Epoch 6: val_accuracy did not improve from 0.70889\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - AUC: 0.6607 - Precision: 0.6601 - Recall: 0.6596 - accuracy: 0.6669 - loss: 0.7664 - val_AUC: 0.7623 - val_Precision: 0.6305 - val_Recall: 0.6825 - val_accuracy: 0.6811 - val_loss: 0.5834\n",
      "Epoch 7/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - AUC: 0.7122 - Precision: 0.5842 - Recall: 0.6700 - accuracy: 0.6398 - loss: 0.6689\n",
      "Epoch 7: val_accuracy did not improve from 0.70889\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 342ms/step - AUC: 0.7112 - Precision: 0.5858 - Recall: 0.6704 - accuracy: 0.6411 - loss: 0.6729 - val_AUC: 0.7470 - val_Precision: 0.5763 - val_Recall: 0.7650 - val_accuracy: 0.6456 - val_loss: 0.6483\n",
      "Epoch 8/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.7423 - Precision: 0.5911 - Recall: 0.6051 - accuracy: 0.6163 - loss: 0.6415\n",
      "Epoch 8: val_accuracy improved from 0.70889 to 0.71333, saving model to model_81_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - AUC: 0.7426 - Precision: 0.5953 - Recall: 0.6072 - accuracy: 0.6195 - loss: 0.6400 - val_AUC: 0.7892 - val_Precision: 0.6473 - val_Recall: 0.7800 - val_accuracy: 0.7133 - val_loss: 0.5867\n",
      "Epoch 9/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.7788 - Precision: 0.7552 - Recall: 0.7197 - accuracy: 0.7293 - loss: 0.5803\n",
      "Epoch 9: val_accuracy improved from 0.71333 to 0.72778, saving model to model_81_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - AUC: 0.7790 - Precision: 0.7493 - Recall: 0.7203 - accuracy: 0.7284 - loss: 0.5802 - val_AUC: 0.7835 - val_Precision: 0.7045 - val_Recall: 0.6675 - val_accuracy: 0.7278 - val_loss: 0.6042\n",
      "Total time taken for model model_81: 81.57 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - AUC: 0.8046 - Precision: 0.7307 - Recall: 0.6872 - accuracy: 0.7340 - loss: 0.5633\n",
      "Evaluation results for model_81:\n",
      "Loss: 0.5869472026824951, Accuracy: 0.7266666889190674, AUC: 0.7903675436973572, Precision: 0.6984536051750183, Recall: 0.6775000095367432\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.6703 - Precision: 0.4804 - Recall: 0.5340 - accuracy: 0.6302 - loss: 0.8379\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66000, saving model to model_54_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 319ms/step - AUC: 0.6668 - Precision: 0.4807 - Recall: 0.5351 - accuracy: 0.6275 - loss: 0.8463 - val_AUC: 0.7024 - val_Precision: 0.6926 - val_Recall: 0.4225 - val_accuracy: 0.6600 - val_loss: 0.6401\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.7231 - Precision: 0.6879 - Recall: 0.7458 - accuracy: 0.7250 - loss: 0.7670\n",
      "Epoch 2: val_accuracy did not improve from 0.66000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - AUC: 0.7238 - Precision: 0.6897 - Recall: 0.7447 - accuracy: 0.7256 - loss: 0.7654 - val_AUC: 0.5958 - val_Precision: 0.5062 - val_Recall: 0.7175 - val_accuracy: 0.5633 - val_loss: 0.7471\n",
      "Epoch 3/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.6799 - Precision: 0.5485 - Recall: 0.6545 - accuracy: 0.6144 - loss: 0.7331\n",
      "Epoch 3: val_accuracy did not improve from 0.66000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - AUC: 0.6842 - Precision: 0.5562 - Recall: 0.6549 - accuracy: 0.6178 - loss: 0.7331 - val_AUC: 0.7158 - val_Precision: 0.4906 - val_Recall: 0.9175 - val_accuracy: 0.5400 - val_loss: 0.8208\n",
      "Epoch 4/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - AUC: 0.7306 - Precision: 0.7085 - Recall: 0.7094 - accuracy: 0.7462 - loss: 0.6981\n",
      "Epoch 4: val_accuracy did not improve from 0.66000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - AUC: 0.7307 - Precision: 0.7064 - Recall: 0.7024 - accuracy: 0.7415 - loss: 0.6990 - val_AUC: 0.7161 - val_Precision: 0.5858 - val_Recall: 0.7000 - val_accuracy: 0.6467 - val_loss: 0.6290\n",
      "Epoch 5/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.6190 - Precision: 0.4173 - Recall: 0.5058 - accuracy: 0.5271 - loss: 0.8286\n",
      "Epoch 5: val_accuracy improved from 0.66000 to 0.68556, saving model to model_54_best_model.keras\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - AUC: 0.6226 - Precision: 0.4271 - Recall: 0.5167 - accuracy: 0.5333 - loss: 0.8279 - val_AUC: 0.7618 - val_Precision: 0.7241 - val_Recall: 0.4725 - val_accuracy: 0.6856 - val_loss: 0.6024\n",
      "Epoch 6/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.7991 - Precision: 0.6755 - Recall: 0.6872 - accuracy: 0.6814 - loss: 0.5966\n",
      "Epoch 6: val_accuracy did not improve from 0.68556\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - AUC: 0.7979 - Precision: 0.6710 - Recall: 0.6899 - accuracy: 0.6811 - loss: 0.5993 - val_AUC: 0.7643 - val_Precision: 0.6089 - val_Recall: 0.7825 - val_accuracy: 0.6800 - val_loss: 0.6116\n",
      "Epoch 7/10\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.7463 - Precision: 0.6625 - Recall: 0.6676 - accuracy: 0.7104 - loss: 0.6424\n",
      "Epoch 7: val_accuracy did not improve from 0.68556\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - AUC: 0.7430 - Precision: 0.6647 - Recall: 0.6625 - accuracy: 0.7069 - loss: 0.6468 - val_AUC: 0.7149 - val_Precision: 0.5934 - val_Recall: 0.7150 - val_accuracy: 0.6556 - val_loss: 0.6394\n",
      "Epoch 8/10\n",
      "\u001b[1m22/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.7053 - Precision: 0.7175 - Recall: 0.5251 - accuracy: 0.5968 - loss: 0.6761\n",
      "Epoch 8: val_accuracy did not improve from 0.68556\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - AUC: 0.7032 - Precision: 0.7117 - Recall: 0.5302 - accuracy: 0.5979 - loss: 0.6794 - val_AUC: 0.7075 - val_Precision: 0.5712 - val_Recall: 0.7925 - val_accuracy: 0.6433 - val_loss: 0.6812\n",
      "Total time taken for model model_54: 54.76 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - AUC: 0.7206 - Precision: 0.5770 - Recall: 0.8230 - accuracy: 0.6489 - loss: 0.6625\n",
      "Evaluation results for model_54:\n",
      "Loss: 0.67735356092453, Accuracy: 0.6366666555404663, AUC: 0.7076724767684937, Precision: 0.5655296444892883, Recall: 0.7875000238418579\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class TimerAfterFirstIteration(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Initialize a flag to check if it's the first epoch\n",
    "        if epoch == 0 and self.model.history.epoch:  # check for first iteration\n",
    "            self.start_time = time.time()  # Start timer after first iteration\n",
    "            print(f\"Timer started after the first iteration of epoch {epoch + 1}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Stop the timer after the epoch ends and calculate time taken after the first iteration\n",
    "        if hasattr(self, 'start_time'):\n",
    "            self.end_time = time.time()\n",
    "            elapsed_time = self.end_time - self.start_time\n",
    "            print(f\"Time taken after the first iteration for epoch {epoch + 1}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(target_size, model_name):\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    # Create image generators for the given target_size\n",
    "    train_datagen = image.ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    val_datagen = image.ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    # Train and validation generators with the current target size\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=4,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    # Load and build the model\n",
    "    base_model = tf.keras.applications.EfficientNetB3(weights='imagenet', input_shape=(target_size[0], target_size[1], 3), include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GaussianNoise(0.25))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GaussianNoise(0.25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC', 'Precision', 'Recall'])\n",
    "    \n",
    "    # Set up callbacks\n",
    "    es = EarlyStopping(patience=3, monitor='val_loss')\n",
    "    filepath = f'{model_name}_best_model.keras'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    # Add the Timer callback here\n",
    "    timer_callback = TimerAfterFirstIteration()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=24,\n",
    "        callbacks=[checkpoint, es, timer_callback]  # Include the Timer callback\n",
    "    )\n",
    "    \n",
    "    # End overall timer and calculate time taken for complete process\n",
    "    end_time = time.time()  # Stop overall timer after training\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total time taken for model {model_name}: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    evaluation = model.evaluate(validation_generator)\n",
    "    print(f\"Evaluation results for {model_name}:\")\n",
    "    print(f\"Loss: {evaluation[0]}, Accuracy: {evaluation[1]}, AUC: {evaluation[2]}, Precision: {evaluation[3]}, Recall: {evaluation[4]}\")\n",
    "    \n",
    "    return evaluation, elapsed_time\n",
    "\n",
    "\n",
    "results_224, time_224 = train_and_evaluate((224, 224), \"model_224\")\n",
    "results_128, time_128 = train_and_evaluate((128, 128), \"model_128\")\n",
    "results_64, time_64 = train_and_evaluate((64, 64), \"model_64\")\n",
    "\n",
    "results_243, time_243 = train_and_evaluate((243, 243), \"model_243\")\n",
    "results_162, time_162 = train_and_evaluate((162, 162), \"model_162\")\n",
    "results_81, time_81 = train_and_evaluate((81, 81), \"model_81\")\n",
    "results_54, time_54 = train_and_evaluate((54, 54), \"model_54\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of models:\n",
      "Model with 224x224 resize: Accuracy=0.771, AUC=0.869, Precision=0.708, Recall=0.825, Time=199.10 seconds\n",
      "Model with 128x128 resize: Accuracy=0.761, AUC=0.824, Precision=0.797, Recall=0.62, Time=130.20 seconds\n",
      "Model with 64x64 resize: Accuracy=0.68, AUC=0.762, Precision=0.715, Recall=0.465, Time=74.69 seconds\n",
      "\n",
      "\n",
      "Model with 243x243 resize: Accuracy=0.759, AUC=0.858, Precision=0.715, Recall=0.76, Time=283.38 seconds\n",
      "Model with 162x162 resize: Accuracy=0.722, AUC=0.805, Precision=0.795, Recall=0.505, Time=89.30 seconds\n",
      "Model with 81x81 resize: Accuracy=0.727, AUC=0.79, Precision=0.698, Recall=0.678, Time=81.57 seconds\n",
      "Model with 54x54 resize: Accuracy=0.637, AUC=0.708, Precision=0.566, Recall=0.788, Time=54.76 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Comparison of results with rounded metrics\n",
    "print(f\"\\nComparison of models:\")\n",
    "\n",
    "print(f\"Model with 224x224 resize: Accuracy={round(results_224[1], 3)}, AUC={round(results_224[2], 3)}, Precision={round(results_224[3], 3)}, Recall={round(results_224[4], 3)}, Time={time_64:.2f} seconds\")\n",
    "print(f\"Model with 128x128 resize: Accuracy={round(results_128[1], 3)}, AUC={round(results_128[2], 3)}, Precision={round(results_128[3], 3)}, Recall={round(results_128[4], 3)}, Time={time_128:.2f} seconds\")\n",
    "print(f\"Model with 64x64 resize: Accuracy={round(results_64[1], 3)}, AUC={round(results_64[2], 3)}, Precision={round(results_64[3], 3)}, Recall={round(results_64[4], 3)}, Time={time_64:.2f} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Model with 243x243 resize: Accuracy={round(results_243[1], 3)}, AUC={round(results_243[2], 3)}, Precision={round(results_243[3], 3)}, Recall={round(results_243[4], 3)}, Time={time_243:.2f} seconds\")\n",
    "print(f\"Model with 162x162 resize: Accuracy={round(results_162[1], 3)}, AUC={round(results_162[2], 3)}, Precision={round(results_162[3], 3)}, Recall={round(results_162[4], 3)}, Time={time_162:.2f} seconds\")\n",
    "print(f\"Model with 81x81 resize: Accuracy={round(results_81[1],3)}, AUC={round(results_81[2],3)}, Precision={round(results_81[3],3)}, Recall={round(results_81[4],3)}, Time={time_81:.2f} seconds\")\n",
    "print(f\"Model with 54x54 resize: Accuracy={round(results_54[1],3)}, AUC={round(results_54[2],3)}, Precision={round(results_54[3],3)}, Recall={round(results_54[4],3)}, Time={time_54:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
