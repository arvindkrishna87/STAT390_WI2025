Put whatever you did here, except data files. Don't put any data files (tissue images) here, they are too large for github. You may indicate the data your code uses - provide the OneDrive link to that data, or just mention the path to it.

If you wrote any code (python / QuPath / any other language), comment it well, and put it here, along with a Readme file describing the code. If the code is meant to be useful to other people, put instructions in the Readme file on how to use it. You will get extra credit if many people use your code!

If you did literature survey, then put it here as well.

For this presentation, I focused on the third question: How does having a large proportion of pixels as background in the image affect the CNN model's accuracy to classify the image?

I initially started by doing research for studies on this topic. However, there were some issues in finding studes that directly addressed the question we sought to answer. We found studes that talked about removing the background, chaning the colors of the background, and different ways to remove the background, but none of them seemed to be extremely relevant to the context that we have with regards to our model. That said, they did give us indication that improving the ratio of image to background will improve our model, which aligned with our original thoughts based on our understandings of CNNs, but just nothing specific enough to really change the way we aproach the problem. 

Then, Alex and I decided to experiment with images our selves so that we could somewhat simulate how much having a greater proportion of image to background really impacted a model. We took a class together last quarter that trained a few models on images of cats and non-cats for it to be able to distinguish whether an image was a cat or not, so we decided to use that dataset and modeling technique on this experiment. We took the original images of cats and non-cats from the dataset and made the background (everything other than the cat/object) black to mimic how the images in our project will look. We then tried to create new images by cropping them to remove as much of the black background as possible, and we then created more images by adding a layer of 4 pixels of black padding around the images. We used all three of those datasets of images (one with just a black background, one with backgrounds cropped, and one with another layer of black around the image) and compared them to see how a black background affected the model's accuracy. 

We trained two models with these datasets, a 4 layer model and a 2 layer model, and the results were interesting. We expected the cropped images (second dataset) to perform the best, as it had the greatest ratio of image to background. However, the original images performed the best on the two models we tested, albeit only marginally (62.5% compared to 62.2% accuracy on the first model, 59.4% compared to 57.8% on the second). The third dataset performed the worst on the first model (though performed the same as the second dataset on the second model), which was expected, however we did not expect it to perform significantly worse as it did (48.9% accuracy).

Overall, this experiment may not have provided too much clarity about how much the proportion of image to background affects the model, similar to the studies we found.


Update: when asked about why the third model performed so poorly, we did more research. I continued the experiment, this time altering the original cropped images to include padding layers of 2, 4, 6, and 8 pixels, compared to just 4 pixels of black background padding tyat we did in the original experiment. All of these models performed significanly worse than the other two original datasets, with them achieving accuracies of 55.6%, 48.9%, 51.1%, and 53.3%, respectively. It's difficult to figure out why a layer of 4 pixels performed the worst out of all of them, but the general trend of them all performing worse than the other two datasets fits with what we expected. The padding causing the model to perform worse can be explained by a few reasons: 
- The additional layers of black pixels add irrelevant information to the images, so the models spend extra effort into looking for meaning from these meaningless pixels, and it likely takes away from the focus of the actual image.
- Adding a layer of black padding can change the relative position of some of the images. For example, if a cat was originally in the corner of an image, the padding would have moved it away from the corner to the center of the image. However, when it’s in the corner it can maybe be implied that there’s some more of the cat that isn’t in the image, but when you take it away then the computer has to assume that the corner-like part is just what the full cat looks like (since the shape of the cat in the image will stay the same), but that’s not true since cats don’t have a triangle shaped butt.



