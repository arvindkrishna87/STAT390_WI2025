{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image size is: 224x224\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "img = Image.open('/Users/wwang/Desktop/work/ultrasound breast classification/train/benign/benign (108)-sharpened-sharpened.png')\n",
    "\n",
    "# Get the image's size (width, height)\n",
    "width, height = img.size\n",
    "print(f\"The image size is: {width}x{height}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import * \n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= '/Users/wwang/Desktop/work/ultrasound breast classification/train'\n",
    "test_path='/Users/wwang/Desktop/work/ultrasound breast classification/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "val_datagen= image.ImageDataGenerator(    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (112,112),\n",
    "    batch_size = 4,\n",
    "    class_mode = 'binary')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size = (112,112),\n",
    "    batch_size = 4,\n",
    "    shuffle=True,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gaussian_noise (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gaussian_noise_1                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb3 (\u001b[38;5;33mFunctional\u001b[0m)     │ ?                      │    \u001b[38;5;34m10,783,535\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gaussian_noise (\u001b[38;5;33mGaussianNoise\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gaussian_noise_1                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> (41.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,783,535\u001b[0m (41.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> (41.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,783,535\u001b[0m (41.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB3(weights='imagenet', input_shape=(224,224,3), include_top=False)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GaussianNoise(0.25))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GaussianNoise(0.25))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy','AUC','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - AUC: 0.5500 - Precision: 0.5364 - Recall: 0.5320 - accuracy: 0.5324 - loss: 1.0642\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69333, saving model to model_224_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 616ms/step - AUC: 0.5519 - Precision: 0.5380 - Recall: 0.5333 - accuracy: 0.5340 - loss: 1.0614 - val_AUC: 0.7757 - val_Precision: 0.6442 - val_Recall: 0.6925 - val_accuracy: 0.6933 - val_loss: 0.5647\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - AUC: 0.7154 - Precision: 0.7074 - Recall: 0.6179 - accuracy: 0.6271 - loss: 0.7004\n",
      "Epoch 2: val_accuracy improved from 0.69333 to 0.73778, saving model to model_224_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 490ms/step - AUC: 0.7160 - Precision: 0.7070 - Recall: 0.6188 - accuracy: 0.6277 - loss: 0.6999 - val_AUC: 0.8360 - val_Precision: 0.7470 - val_Recall: 0.6200 - val_accuracy: 0.7378 - val_loss: 0.5022\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - AUC: 0.8062 - Precision: 0.7601 - Recall: 0.7397 - accuracy: 0.7593 - loss: 0.5688\n",
      "Epoch 3: val_accuracy improved from 0.73778 to 0.75333, saving model to model_224_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 484ms/step - AUC: 0.8056 - Precision: 0.7591 - Recall: 0.7396 - accuracy: 0.7586 - loss: 0.5699 - val_AUC: 0.8526 - val_Precision: 0.7987 - val_Recall: 0.5950 - val_accuracy: 0.7533 - val_loss: 0.4946\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - AUC: 0.8075 - Precision: 0.5787 - Recall: 0.7898 - accuracy: 0.7003 - loss: 0.5886\n",
      "Epoch 4: val_accuracy did not improve from 0.75333\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 468ms/step - AUC: 0.8067 - Precision: 0.5806 - Recall: 0.7876 - accuracy: 0.7002 - loss: 0.5893 - val_AUC: 0.8246 - val_Precision: 0.7236 - val_Recall: 0.6350 - val_accuracy: 0.7300 - val_loss: 0.5288\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - AUC: 0.7345 - Precision: 0.6797 - Recall: 0.6604 - accuracy: 0.6802 - loss: 0.6935\n",
      "Epoch 5: val_accuracy improved from 0.75333 to 0.76444, saving model to model_224_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 490ms/step - AUC: 0.7345 - Precision: 0.6794 - Recall: 0.6605 - accuracy: 0.6800 - loss: 0.6934 - val_AUC: 0.8431 - val_Precision: 0.7448 - val_Recall: 0.7150 - val_accuracy: 0.7644 - val_loss: 0.4993\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - AUC: 0.7641 - Precision: 0.6891 - Recall: 0.7646 - accuracy: 0.7324 - loss: 0.6532\n",
      "Epoch 6: val_accuracy improved from 0.76444 to 0.81667, saving model to model_224_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 497ms/step - AUC: 0.7646 - Precision: 0.6894 - Recall: 0.7642 - accuracy: 0.7325 - loss: 0.6520 - val_AUC: 0.8991 - val_Precision: 0.8466 - val_Recall: 0.7175 - val_accuracy: 0.8167 - val_loss: 0.4097\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - AUC: 0.7897 - Precision: 0.7273 - Recall: 0.6573 - accuracy: 0.7015 - loss: 0.5753\n",
      "Epoch 7: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 499ms/step - AUC: 0.7900 - Precision: 0.7283 - Recall: 0.6579 - accuracy: 0.7019 - loss: 0.5750 - val_AUC: 0.9018 - val_Precision: 0.7511 - val_Recall: 0.8225 - val_accuracy: 0.8000 - val_loss: 0.4044\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - AUC: 0.8548 - Precision: 0.8159 - Recall: 0.7523 - accuracy: 0.7620 - loss: 0.4951\n",
      "Epoch 8: val_accuracy improved from 0.81667 to 0.81889, saving model to model_224_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 497ms/step - AUC: 0.8545 - Precision: 0.8158 - Recall: 0.7524 - accuracy: 0.7621 - loss: 0.4954 - val_AUC: 0.8996 - val_Precision: 0.8160 - val_Recall: 0.7650 - val_accuracy: 0.8189 - val_loss: 0.4057\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - AUC: 0.7801 - Precision: 0.5986 - Recall: 0.7773 - accuracy: 0.6876 - loss: 0.6099\n",
      "Epoch 9: val_accuracy did not improve from 0.81889\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 513ms/step - AUC: 0.7804 - Precision: 0.5999 - Recall: 0.7773 - accuracy: 0.6881 - loss: 0.6092 - val_AUC: 0.8889 - val_Precision: 0.8282 - val_Recall: 0.6750 - val_accuracy: 0.7933 - val_loss: 0.4282\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - AUC: 0.8256 - Precision: 0.7843 - Recall: 0.7709 - accuracy: 0.7657 - loss: 0.5440\n",
      "Epoch 10: val_accuracy did not improve from 0.81889\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 486ms/step - AUC: 0.8254 - Precision: 0.7833 - Recall: 0.7711 - accuracy: 0.7653 - loss: 0.5439 - val_AUC: 0.8894 - val_Precision: 0.8958 - val_Recall: 0.5800 - val_accuracy: 0.7833 - val_loss: 0.5047\n",
      "Time taken for model model_224: 254.90 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - AUC: 0.8867 - Precision: 0.8582 - Recall: 0.5130 - accuracy: 0.7501 - loss: 0.5313\n",
      "Evaluation results for model_224:\n",
      "Loss: 0.5224398970603943, Accuracy: 0.7711111307144165, AUC: 0.8930324912071228, Precision: 0.9041666388511658, Recall: 0.5425000190734863\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - AUC: 0.6444 - Precision: 0.6632 - Recall: 0.6843 - accuracy: 0.6270 - loss: 0.9036\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66778, saving model to model_128_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 279ms/step - AUC: 0.6454 - Precision: 0.6628 - Recall: 0.6830 - accuracy: 0.6267 - loss: 0.9047 - val_AUC: 0.7303 - val_Precision: 0.6634 - val_Recall: 0.5125 - val_accuracy: 0.6678 - val_loss: 0.6432\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - AUC: 0.7752 - Precision: 0.5697 - Recall: 0.7276 - accuracy: 0.6648 - loss: 0.8566\n",
      "Epoch 2: val_accuracy improved from 0.66778 to 0.71667, saving model to model_128_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - AUC: 0.7743 - Precision: 0.5710 - Recall: 0.7274 - accuracy: 0.6652 - loss: 0.8561 - val_AUC: 0.8108 - val_Precision: 0.6424 - val_Recall: 0.8175 - val_accuracy: 0.7167 - val_loss: 0.5585\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - AUC: 0.8407 - Precision: 0.7299 - Recall: 0.7947 - accuracy: 0.7674 - loss: 0.5214\n",
      "Epoch 3: val_accuracy improved from 0.71667 to 0.78000, saving model to model_128_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - AUC: 0.8391 - Precision: 0.7279 - Recall: 0.7927 - accuracy: 0.7657 - loss: 0.5240 - val_AUC: 0.8643 - val_Precision: 0.7525 - val_Recall: 0.7525 - val_accuracy: 0.7800 - val_loss: 0.4539\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - AUC: 0.7654 - Precision: 0.6424 - Recall: 0.7018 - accuracy: 0.6694 - loss: 0.6559\n",
      "Epoch 4: val_accuracy did not improve from 0.78000\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 252ms/step - AUC: 0.7650 - Precision: 0.6430 - Recall: 0.7010 - accuracy: 0.6694 - loss: 0.6560 - val_AUC: 0.8651 - val_Precision: 0.7962 - val_Recall: 0.6250 - val_accuracy: 0.7622 - val_loss: 0.5055\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - AUC: 0.7296 - Precision: 0.6304 - Recall: 0.6925 - accuracy: 0.6508 - loss: 0.7111\n",
      "Epoch 5: val_accuracy did not improve from 0.78000\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - AUC: 0.7302 - Precision: 0.6322 - Recall: 0.6931 - accuracy: 0.6517 - loss: 0.7101 - val_AUC: 0.8689 - val_Precision: 0.8523 - val_Recall: 0.5625 - val_accuracy: 0.7622 - val_loss: 0.5188\n",
      "Epoch 6/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - AUC: 0.7766 - Precision: 0.6389 - Recall: 0.6802 - accuracy: 0.6706 - loss: 0.6290\n",
      "Epoch 6: val_accuracy improved from 0.78000 to 0.78778, saving model to model_128_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 251ms/step - AUC: 0.7764 - Precision: 0.6405 - Recall: 0.6799 - accuracy: 0.6712 - loss: 0.6284 - val_AUC: 0.8574 - val_Precision: 0.8101 - val_Recall: 0.6825 - val_accuracy: 0.7878 - val_loss: 0.4848\n",
      "Time taken for model model_128: 82.99 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - AUC: 0.8611 - Precision: 0.7907 - Recall: 0.6953 - accuracy: 0.7893 - loss: 0.4632\n",
      "Evaluation results for model_128:\n",
      "Loss: 0.4614229202270508, Accuracy: 0.7855555415153503, AUC: 0.8659900426864624, Precision: 0.7982708811759949, Recall: 0.6924999952316284\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.6280 - Precision: 0.5617 - Recall: 0.5479 - accuracy: 0.5914 - loss: 0.8630\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55889, saving model to model_64_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - AUC: 0.6290 - Precision: 0.5627 - Recall: 0.5476 - accuracy: 0.5925 - loss: 0.8629 - val_AUC: 0.6271 - val_Precision: 0.5024 - val_Recall: 0.7900 - val_accuracy: 0.5589 - val_loss: 0.7948\n",
      "Epoch 2/10\n",
      "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.5957 - Precision: 0.5913 - Recall: 0.6468 - accuracy: 0.6403 - loss: 0.9143\n",
      "Epoch 2: val_accuracy improved from 0.55889 to 0.62667, saving model to model_64_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - AUC: 0.6015 - Precision: 0.5938 - Recall: 0.6496 - accuracy: 0.6432 - loss: 0.9048 - val_AUC: 0.6875 - val_Precision: 0.5714 - val_Recall: 0.6400 - val_accuracy: 0.6267 - val_loss: 0.6534\n",
      "Epoch 3/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.6325 - Precision: 0.5463 - Recall: 0.5826 - accuracy: 0.6317 - loss: 0.8135\n",
      "Epoch 3: val_accuracy improved from 0.62667 to 0.62889, saving model to model_64_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - AUC: 0.6345 - Precision: 0.5491 - Recall: 0.5834 - accuracy: 0.6324 - loss: 0.8105 - val_AUC: 0.6490 - val_Precision: 0.6241 - val_Recall: 0.4150 - val_accuracy: 0.6289 - val_loss: 0.6887\n",
      "Epoch 4/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.5866 - Precision: 0.6233 - Recall: 0.5279 - accuracy: 0.5517 - loss: 0.8987\n",
      "Epoch 4: val_accuracy improved from 0.62889 to 0.70444, saving model to model_64_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - AUC: 0.5877 - Precision: 0.6223 - Recall: 0.5279 - accuracy: 0.5520 - loss: 0.8948 - val_AUC: 0.7846 - val_Precision: 0.6390 - val_Recall: 0.7700 - val_accuracy: 0.7044 - val_loss: 0.5758\n",
      "Epoch 5/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.7813 - Precision: 0.7154 - Recall: 0.6789 - accuracy: 0.6966 - loss: 0.5683\n",
      "Epoch 5: val_accuracy improved from 0.70444 to 0.71222, saving model to model_64_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - AUC: 0.7801 - Precision: 0.7132 - Recall: 0.6773 - accuracy: 0.6953 - loss: 0.5693 - val_AUC: 0.7567 - val_Precision: 0.6860 - val_Recall: 0.6500 - val_accuracy: 0.7122 - val_loss: 0.6021\n",
      "Epoch 6/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.7033 - Precision: 0.6472 - Recall: 0.6411 - accuracy: 0.6388 - loss: 0.6800\n",
      "Epoch 6: val_accuracy did not improve from 0.71222\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - AUC: 0.7028 - Precision: 0.6456 - Recall: 0.6412 - accuracy: 0.6381 - loss: 0.6802 - val_AUC: 0.7229 - val_Precision: 0.6284 - val_Recall: 0.6425 - val_accuracy: 0.6722 - val_loss: 0.6466\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.6457 - Precision: 0.7115 - Recall: 0.6455 - accuracy: 0.6457 - loss: 0.7124\n",
      "Epoch 7: val_accuracy did not improve from 0.71222\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - AUC: 0.6464 - Precision: 0.7107 - Recall: 0.6455 - accuracy: 0.6458 - loss: 0.7116 - val_AUC: 0.7791 - val_Precision: 0.6981 - val_Recall: 0.5375 - val_accuracy: 0.6911 - val_loss: 0.5685\n",
      "Epoch 8/10\n",
      "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.6747 - Precision: 0.6499 - Recall: 0.6242 - accuracy: 0.6423 - loss: 0.6816\n",
      "Epoch 8: val_accuracy did not improve from 0.71222\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - AUC: 0.6761 - Precision: 0.6476 - Recall: 0.6243 - accuracy: 0.6419 - loss: 0.6806 - val_AUC: 0.7073 - val_Precision: 0.6776 - val_Recall: 0.5150 - val_accuracy: 0.6756 - val_loss: 0.6759\n",
      "Epoch 9/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.7973 - Precision: 0.7628 - Recall: 0.7466 - accuracy: 0.7426 - loss: 0.5569\n",
      "Epoch 9: val_accuracy improved from 0.71222 to 0.71889, saving model to model_64_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - AUC: 0.7951 - Precision: 0.7605 - Recall: 0.7439 - accuracy: 0.7401 - loss: 0.5599 - val_AUC: 0.7804 - val_Precision: 0.6971 - val_Recall: 0.6500 - val_accuracy: 0.7189 - val_loss: 0.5653\n",
      "Epoch 10/10\n",
      "\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - AUC: 0.7045 - Precision: 0.5536 - Recall: 0.6211 - accuracy: 0.6285 - loss: 0.6736\n",
      "Epoch 10: val_accuracy did not improve from 0.71889\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - AUC: 0.7044 - Precision: 0.5571 - Recall: 0.6201 - accuracy: 0.6299 - loss: 0.6731 - val_AUC: 0.7638 - val_Precision: 0.6012 - val_Recall: 0.7275 - val_accuracy: 0.6644 - val_loss: 0.6115\n",
      "Time taken for model model_64: 69.70 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - AUC: 0.8095 - Precision: 0.6917 - Recall: 0.7403 - accuracy: 0.7257 - loss: 0.5372\n",
      "Evaluation results for model_64:\n",
      "Loss: 0.5582898855209351, Accuracy: 0.695555567741394, AUC: 0.7985349893569946, Precision: 0.6363636255264282, Recall: 0.7350000143051147\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - AUC: 0.6082 - Precision: 0.5574 - Recall: 0.6170 - accuracy: 0.5767 - loss: 0.9077\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70000, saving model to model_243_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 632ms/step - AUC: 0.6099 - Precision: 0.5589 - Recall: 0.6181 - accuracy: 0.5781 - loss: 0.9060 - val_AUC: 0.7795 - val_Precision: 0.6477 - val_Recall: 0.7125 - val_accuracy: 0.7000 - val_loss: 0.5811\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - AUC: 0.6969 - Precision: 0.6870 - Recall: 0.6698 - accuracy: 0.6729 - loss: 0.8235\n",
      "Epoch 2: val_accuracy improved from 0.70000 to 0.72667, saving model to model_243_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 615ms/step - AUC: 0.6976 - Precision: 0.6867 - Recall: 0.6705 - accuracy: 0.6729 - loss: 0.8216 - val_AUC: 0.8095 - val_Precision: 0.6674 - val_Recall: 0.7675 - val_accuracy: 0.7267 - val_loss: 0.5620\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - AUC: 0.7331 - Precision: 0.6515 - Recall: 0.6203 - accuracy: 0.6297 - loss: 0.7335\n",
      "Epoch 3: val_accuracy improved from 0.72667 to 0.74333, saving model to model_243_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 630ms/step - AUC: 0.7331 - Precision: 0.6510 - Recall: 0.6208 - accuracy: 0.6302 - loss: 0.7327 - val_AUC: 0.8512 - val_Precision: 0.9082 - val_Recall: 0.4700 - val_accuracy: 0.7433 - val_loss: 0.5701\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - AUC: 0.7281 - Precision: 0.5865 - Recall: 0.6115 - accuracy: 0.6089 - loss: 0.6201\n",
      "Epoch 4: val_accuracy improved from 0.74333 to 0.76111, saving model to model_243_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 596ms/step - AUC: 0.7293 - Precision: 0.5880 - Recall: 0.6128 - accuracy: 0.6101 - loss: 0.6189 - val_AUC: 0.8616 - val_Precision: 0.7507 - val_Recall: 0.6925 - val_accuracy: 0.7611 - val_loss: 0.4653\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - AUC: 0.8566 - Precision: 0.7691 - Recall: 0.7192 - accuracy: 0.7666 - loss: 0.4584\n",
      "Epoch 5: val_accuracy improved from 0.76111 to 0.79667, saving model to model_243_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 571ms/step - AUC: 0.8558 - Precision: 0.7672 - Recall: 0.7184 - accuracy: 0.7656 - loss: 0.4597 - val_AUC: 0.8858 - val_Precision: 0.8401 - val_Recall: 0.6700 - val_accuracy: 0.7967 - val_loss: 0.4541\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - AUC: 0.7855 - Precision: 0.5878 - Recall: 0.7210 - accuracy: 0.6888 - loss: 0.5988\n",
      "Epoch 6: val_accuracy did not improve from 0.79667\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 586ms/step - AUC: 0.7853 - Precision: 0.5900 - Recall: 0.7201 - accuracy: 0.6890 - loss: 0.5994 - val_AUC: 0.8998 - val_Precision: 0.9420 - val_Recall: 0.4875 - val_accuracy: 0.7589 - val_loss: 0.5592\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - AUC: 0.7756 - Precision: 0.6744 - Recall: 0.6635 - accuracy: 0.6802 - loss: 0.6169\n",
      "Epoch 7: val_accuracy improved from 0.79667 to 0.80000, saving model to model_243_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 578ms/step - AUC: 0.7756 - Precision: 0.6753 - Recall: 0.6637 - accuracy: 0.6803 - loss: 0.6168 - val_AUC: 0.8678 - val_Precision: 0.8056 - val_Recall: 0.7250 - val_accuracy: 0.8000 - val_loss: 0.4758\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - AUC: 0.8603 - Precision: 0.7635 - Recall: 0.7843 - accuracy: 0.7853 - loss: 0.4758\n",
      "Epoch 8: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 601ms/step - AUC: 0.8591 - Precision: 0.7628 - Recall: 0.7830 - accuracy: 0.7842 - loss: 0.4775 - val_AUC: 0.8821 - val_Precision: 0.7536 - val_Recall: 0.7950 - val_accuracy: 0.7933 - val_loss: 0.4357\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - AUC: 0.8586 - Precision: 0.7622 - Recall: 0.8274 - accuracy: 0.7807 - loss: 0.4650\n",
      "Epoch 9: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 589ms/step - AUC: 0.8584 - Precision: 0.7622 - Recall: 0.8270 - accuracy: 0.7805 - loss: 0.4652 - val_AUC: 0.8930 - val_Precision: 0.7764 - val_Recall: 0.7725 - val_accuracy: 0.8000 - val_loss: 0.4158\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - AUC: 0.8544 - Precision: 0.8205 - Recall: 0.7491 - accuracy: 0.7578 - loss: 0.4760\n",
      "Epoch 10: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 576ms/step - AUC: 0.8547 - Precision: 0.8208 - Recall: 0.7492 - accuracy: 0.7579 - loss: 0.4760 - val_AUC: 0.8762 - val_Precision: 0.8442 - val_Recall: 0.6500 - val_accuracy: 0.7911 - val_loss: 0.4893\n",
      "Time taken for model model_243: 300.33 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 106ms/step - AUC: 0.8608 - Precision: 0.8059 - Recall: 0.6374 - accuracy: 0.7828 - loss: 0.5381\n",
      "Evaluation results for model_243:\n",
      "Loss: 0.521985650062561, Accuracy: 0.7822222113609314, AUC: 0.8677050471305847, Precision: 0.8207547068595886, Recall: 0.6524999737739563\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - AUC: 0.6098 - Precision: 0.5376 - Recall: 0.5166 - accuracy: 0.5993 - loss: 0.8742\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71667, saving model to model_162_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 398ms/step - AUC: 0.6109 - Precision: 0.5388 - Recall: 0.5181 - accuracy: 0.5998 - loss: 0.8733 - val_AUC: 0.8516 - val_Precision: 0.6270 - val_Recall: 0.8950 - val_accuracy: 0.7167 - val_loss: 0.5430\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - AUC: 0.8061 - Precision: 0.6830 - Recall: 0.7340 - accuracy: 0.7184 - loss: 0.5966\n",
      "Epoch 2: val_accuracy improved from 0.71667 to 0.72222, saving model to model_162_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 361ms/step - AUC: 0.8057 - Precision: 0.6831 - Recall: 0.7332 - accuracy: 0.7177 - loss: 0.5975 - val_AUC: 0.8557 - val_Precision: 0.6302 - val_Recall: 0.9075 - val_accuracy: 0.7222 - val_loss: 0.5564\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - AUC: 0.6734 - Precision: 0.5188 - Recall: 0.5845 - accuracy: 0.5786 - loss: 0.8432\n",
      "Epoch 3: val_accuracy improved from 0.72222 to 0.79222, saving model to model_162_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - AUC: 0.6744 - Precision: 0.5209 - Recall: 0.5854 - accuracy: 0.5796 - loss: 0.8408 - val_AUC: 0.8738 - val_Precision: 0.7448 - val_Recall: 0.8100 - val_accuracy: 0.7922 - val_loss: 0.4540\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - AUC: 0.8497 - Precision: 0.7032 - Recall: 0.8326 - accuracy: 0.7659 - loss: 0.5594\n",
      "Epoch 4: val_accuracy did not improve from 0.79222\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - AUC: 0.8492 - Precision: 0.7038 - Recall: 0.8306 - accuracy: 0.7653 - loss: 0.5601 - val_AUC: 0.8783 - val_Precision: 0.7404 - val_Recall: 0.7700 - val_accuracy: 0.7778 - val_loss: 0.4440\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - AUC: 0.6543 - Precision: 0.5817 - Recall: 0.7149 - accuracy: 0.6587 - loss: 0.9450\n",
      "Epoch 5: val_accuracy did not improve from 0.79222\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - AUC: 0.6552 - Precision: 0.5825 - Recall: 0.7141 - accuracy: 0.6585 - loss: 0.9418 - val_AUC: 0.8303 - val_Precision: 0.7889 - val_Recall: 0.5700 - val_accuracy: 0.7411 - val_loss: 0.5688\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - AUC: 0.8259 - Precision: 0.7611 - Recall: 0.7171 - accuracy: 0.7275 - loss: 0.5431\n",
      "Epoch 6: val_accuracy improved from 0.79222 to 0.80556, saving model to model_162_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 363ms/step - AUC: 0.8257 - Precision: 0.7605 - Recall: 0.7176 - accuracy: 0.7279 - loss: 0.5433 - val_AUC: 0.8889 - val_Precision: 0.8099 - val_Recall: 0.7350 - val_accuracy: 0.8056 - val_loss: 0.4113\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - AUC: 0.8093 - Precision: 0.6933 - Recall: 0.7154 - accuracy: 0.7225 - loss: 0.5997\n",
      "Epoch 7: val_accuracy did not improve from 0.80556\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 359ms/step - AUC: 0.8089 - Precision: 0.6930 - Recall: 0.7154 - accuracy: 0.7224 - loss: 0.5996 - val_AUC: 0.8718 - val_Precision: 0.7784 - val_Recall: 0.7025 - val_accuracy: 0.7789 - val_loss: 0.4454\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - AUC: 0.6433 - Precision: 0.5353 - Recall: 0.6377 - accuracy: 0.5785 - loss: 0.7477\n",
      "Epoch 8: val_accuracy did not improve from 0.80556\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - AUC: 0.6447 - Precision: 0.5382 - Recall: 0.6375 - accuracy: 0.5800 - loss: 0.7460 - val_AUC: 0.8909 - val_Precision: 0.8903 - val_Recall: 0.5275 - val_accuracy: 0.7611 - val_loss: 0.5266\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - AUC: 0.7611 - Precision: 0.5632 - Recall: 0.6764 - accuracy: 0.6331 - loss: 0.5931\n",
      "Epoch 9: val_accuracy did not improve from 0.80556\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - AUC: 0.7615 - Precision: 0.5647 - Recall: 0.6770 - accuracy: 0.6341 - loss: 0.5926 - val_AUC: 0.8991 - val_Precision: 0.8858 - val_Recall: 0.6400 - val_accuracy: 0.8033 - val_loss: 0.4467\n",
      "Time taken for model model_162: 165.18 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - AUC: 0.9258 - Precision: 0.8873 - Recall: 0.6753 - accuracy: 0.8205 - loss: 0.3792\n",
      "Evaluation results for model_162:\n",
      "Loss: 0.41637957096099854, Accuracy: 0.804444432258606, AUC: 0.9115625619888306, Precision: 0.8809523582458496, Recall: 0.6474999785423279\n",
      "Found 8116 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.6106 - Precision: 0.5597 - Recall: 0.5675 - accuracy: 0.5526 - loss: 1.0072\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62111, saving model to model_81_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 208ms/step - AUC: 0.6115 - Precision: 0.5623 - Recall: 0.5689 - accuracy: 0.5541 - loss: 1.0058 - val_AUC: 0.6710 - val_Precision: 0.5688 - val_Recall: 0.6100 - val_accuracy: 0.6211 - val_loss: 0.6629\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.6403 - Precision: 0.4921 - Recall: 0.6413 - accuracy: 0.5650 - loss: 0.8793\n",
      "Epoch 2: val_accuracy improved from 0.62111 to 0.70667, saving model to model_81_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - AUC: 0.6404 - Precision: 0.4932 - Recall: 0.6411 - accuracy: 0.5655 - loss: 0.8782 - val_AUC: 0.7892 - val_Precision: 0.7329 - val_Recall: 0.5350 - val_accuracy: 0.7067 - val_loss: 0.5575\n",
      "Epoch 3/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.5650 - Precision: 0.6263 - Recall: 0.5719 - accuracy: 0.5424 - loss: 0.9172\n",
      "Epoch 3: val_accuracy did not improve from 0.70667\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - AUC: 0.5672 - Precision: 0.6282 - Recall: 0.5731 - accuracy: 0.5445 - loss: 0.9131 - val_AUC: 0.7688 - val_Precision: 0.6430 - val_Recall: 0.7025 - val_accuracy: 0.6944 - val_loss: 0.5914\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.6895 - Precision: 0.6329 - Recall: 0.6479 - accuracy: 0.6014 - loss: 0.7135\n",
      "Epoch 4: val_accuracy did not improve from 0.70667\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - AUC: 0.6893 - Precision: 0.6325 - Recall: 0.6481 - accuracy: 0.6017 - loss: 0.7142 - val_AUC: 0.7450 - val_Precision: 0.7321 - val_Recall: 0.5125 - val_accuracy: 0.7000 - val_loss: 0.7099\n",
      "Epoch 5/10\n",
      "\u001b[1m49/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - AUC: 0.7773 - Precision: 0.6939 - Recall: 0.7853 - accuracy: 0.7237 - loss: 0.6348\n",
      "Epoch 5: val_accuracy improved from 0.70667 to 0.71889, saving model to model_81_best_model.keras\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - AUC: 0.7754 - Precision: 0.6934 - Recall: 0.7828 - accuracy: 0.7220 - loss: 0.6373 - val_AUC: 0.8046 - val_Precision: 0.6738 - val_Recall: 0.7125 - val_accuracy: 0.7189 - val_loss: 0.5640\n",
      "Time taken for model model_81: 54.60 seconds\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - AUC: 0.8120 - Precision: 0.6833 - Recall: 0.7462 - accuracy: 0.7354 - loss: 0.5664\n",
      "Evaluation results for model_81:\n",
      "Loss: 0.5391029715538025, Accuracy: 0.7388888597488403, AUC: 0.825124979019165, Precision: 0.6914153099060059, Recall: 0.7450000047683716\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "# es=EarlyStopping(patience=3,monitor='val_loss')\n",
    "# filepath='best_model.keras'\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# print(\"Processing without padding:\")\n",
    "\n",
    "# # Train the model with reduced steps_per_epoch (e.g., 10 batches per epoch)\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=3,  # Shorten epochs to just 3 for quicker testing\n",
    "#     validation_data=validation_generator,\n",
    "#     steps_per_epoch=10,  # Reduce the number of steps (batches) per epoch\n",
    "#     callbacks=[checkpoint, es]\n",
    "# )\n",
    "\n",
    "def train_and_evaluate(target_size, model_name):\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    # Create image generators for the given target_size\n",
    "    train_datagen = image.ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    val_datagen = image.ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    # Train and validation generators with the current target size\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=4,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    # Load and build the model\n",
    "    base_model = tf.keras.applications.EfficientNetB3(weights='imagenet', input_shape=(target_size[0], target_size[1], 3), include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GaussianNoise(0.25))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GaussianNoise(0.25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC', 'Precision', 'Recall'])\n",
    "    \n",
    "    # Set up callbacks\n",
    "    es = EarlyStopping(patience=3, monitor='val_loss')\n",
    "    filepath = f'{model_name}_best_model.keras'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=50,\n",
    "        callbacks=[checkpoint, es]\n",
    "    )\n",
    "    \n",
    "    # End timer and calculate time taken\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken for model {model_name}: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    evaluation = model.evaluate(validation_generator)\n",
    "    print(f\"Evaluation results for {model_name}:\")\n",
    "    print(f\"Loss: {evaluation[0]}, Accuracy: {evaluation[1]}, AUC: {evaluation[2]}, Precision: {evaluation[3]}, Recall: {evaluation[4]}\")\n",
    "    \n",
    "    return evaluation, elapsed_time\n",
    "\n",
    "results_224, time_224 = train_and_evaluate((224, 224), \"model_224\")\n",
    "results_128, time_128 = train_and_evaluate((128, 128), \"model_128\")\n",
    "results_64, time_64 = train_and_evaluate((64, 64), \"model_64\")\n",
    "results_243, time_243 = train_and_evaluate((243, 243), \"model_243\")\n",
    "results_162, time_162 = train_and_evaluate((162, 162), \"model_162\")\n",
    "results_81, time_81 = train_and_evaluate((81, 81), \"model_81\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of models:\n",
      "Model with 224x224 resize: Accuracy=0.771, AUC=0.893, Precision=0.904, Recall=0.543, Time=69.70 seconds\n",
      "Model with 128x128 resize: Accuracy=0.786, AUC=0.866, Precision=0.798, Recall=0.692, Time=82.99 seconds\n",
      "Model with 64x64 resize: Accuracy=0.696, AUC=0.799, Precision=0.636, Recall=0.735, Time=69.70 seconds\n",
      "\n",
      "\n",
      "Model with 243x243 resize: Accuracy=0.782, AUC=0.868, Precision=0.821, Recall=0.652, Time=300.33 seconds\n",
      "Model with 162x162 resize: Accuracy=0.804, AUC=0.912, Precision=0.881, Recall=0.647, Time=165.18 seconds\n",
      "Model with 81x81 resize: Accuracy=0.739, AUC=0.825, Precision=0.691, Recall=0.745, Time=54.60 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Comparison of results with rounded metrics\n",
    "print(f\"\\nComparison of models:\")\n",
    "\n",
    "print(f\"Model with 224x224 resize: Accuracy={round(results_224[1], 3)}, AUC={round(results_224[2], 3)}, Precision={round(results_224[3], 3)}, Recall={round(results_224[4], 3)}, Time={time_64:.2f} seconds\")\n",
    "print(f\"Model with 128x128 resize: Accuracy={round(results_128[1], 3)}, AUC={round(results_128[2], 3)}, Precision={round(results_128[3], 3)}, Recall={round(results_128[4], 3)}, Time={time_128:.2f} seconds\")\n",
    "print(f\"Model with 64x64 resize: Accuracy={round(results_64[1], 3)}, AUC={round(results_64[2], 3)}, Precision={round(results_64[3], 3)}, Recall={round(results_64[4], 3)}, Time={time_64:.2f} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Model with 243x243 resize: Accuracy={round(results_243[1], 3)}, AUC={round(results_243[2], 3)}, Precision={round(results_243[3], 3)}, Recall={round(results_243[4], 3)}, Time={time_243:.2f} seconds\")\n",
    "print(f\"Model with 162x162 resize: Accuracy={round(results_162[1], 3)}, AUC={round(results_162[2], 3)}, Precision={round(results_162[3], 3)}, Recall={round(results_162[4], 3)}, Time={time_162:.2f} seconds\")\n",
    "print(f\"Model with 81x81 resize: Accuracy={round(results_81[1],3)}, AUC={round(results_81[2],3)}, Precision={round(results_81[3],3)}, Recall={round(results_81[4],3)}, Time={time_81:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must call `compile()` before using the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/trainer.py:961\u001b[0m, in \u001b[0;36mTrainer._assert_compile_called\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: You must call `compile()` before using the model."
     ]
    }
   ],
   "source": [
    "model.evaluate(train_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
