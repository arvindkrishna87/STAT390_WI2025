{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95880631-67d7-4cb1-87d1-20bd361d94b2",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "To ensure this script works correctly, please follow the instructions below:         \n",
    "1. Run Cara's automation script to generate the 'processed_images' directory         \n",
    "2. Ensure that each file is named the same way (with upper and lower case letters):\n",
    "        patient ID + strain type + ROI number (separated by underscores)\n",
    "3. Run the script and select the 'processed_images' directory   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab5edb9f-13b3-46f7-a9c3-711c2363700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "from itertools import product, chain\n",
    "from collections import defaultdict\n",
    "from skimage import morphology\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e51028-c6a7-4b4c-8e5a-0cb1b867b73e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GUI Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0406ee4-e27e-4ec1-bf6a-c71e0a45d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the gui once both selections are submitted\n",
    "def submit():\n",
    "    if selected['dir']:\n",
    "        root.destroy()\n",
    "    else:\n",
    "        print('Select a directory.')\n",
    "\n",
    "# open directory selecter\n",
    "def select_dir():\n",
    "    dir = filedialog.askdirectory(title = 'Select patient directory')\n",
    "    if dir:\n",
    "        selected['dir'] = dir\n",
    "        dir_label.config(text = f'Selected directory: {dir}')\n",
    "\n",
    "\n",
    "# dictionary to store user selection\n",
    "selected = {'dir': None}\n",
    "\n",
    "# initialize gui window\n",
    "root = tk.Tk()\n",
    "root.title('Patching Pipeline')\n",
    "root.geometry('400x300')\n",
    "\n",
    "# button to select patient directory\n",
    "dir_button = tk.Button(root, text = 'Select patient directory', \n",
    "                       command = select_dir, bg = 'navy', fg = 'white')\n",
    "dir_button.pack(pady = 5)\n",
    "\n",
    "# display selected directory\n",
    "dir_label = tk.Label(root, text = 'No directory selected')\n",
    "dir_label.pack(pady = 0)\n",
    "\n",
    "# add button to submit selections\n",
    "submit_button = tk.Button(root, text = 'Submit', command = submit)\n",
    "submit_button.pack(pady = 0)\n",
    "\n",
    "# run the gui\n",
    "root.mainloop()\n",
    "\n",
    "if selected['dir']:\n",
    "    patient_dir = selected['dir']\n",
    "else:\n",
    "    raise Exception('Please select a directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1ace6-c1f2-4413-aeeb-45187b48aa56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image File Preprocessing\n",
    "In the processed_images directory, each file name is: patient ID + strainType + ROI number. The preprocessing should result in each patient having a separate folder, each with 3 images: h&e, melan, sox10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7129b505-bf35-4140-add8-caa985502b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files():\n",
    "    # Get list of all .tif files in the patient directory\n",
    "    image_files = glob(f'{patient_dir}/*.tif')\n",
    "\n",
    "    # Replace ROI with slice\n",
    "    for image_file in image_files:\n",
    "        new_filename = image_file.replace('ROI', 'slice').replace('mela', 'melan')\n",
    "        os.rename(image_file, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931dbdd-b926-49ce-a1e2-be251f6d31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10e39818-3d0f-4b57-ac15-6bed86386958",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = []\n",
    "for image_file in image_files:\n",
    "    index = image_file.find(\"\\\\\")\n",
    "    result = image_file[index + 1:]\n",
    "    patient_ids.append(result.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a710aa3-5c32-42f1-91a1-9d982c1ae4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1915192 h&e', 'h1915192 melann', 'h1915192 sox10']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db4f42a1-1436-4946-b58c-f0df0e56a630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sox10']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04b4b216-234e-4a7b-88b4-d804a3c4bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is strain_type h&e\n",
      "we are getting here?\n",
      "this is strain_types list ['h&e']\n",
      "this is strain_type melann\n",
      "we are getting here?\n",
      "this is strain_types list ['melann']\n",
      "this is strain_type sox10\n",
      "we are getting here?\n",
      "this is strain_types list ['sox10']\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "patient_ids_with_all_strain_types = set()\n",
    "for patient_id in patient_ids:\n",
    "    strain_types = []\n",
    "    for image_file in image_files:\n",
    "        index = image_file.find(\"\\\\\")\n",
    "        result = image_file[index + 1:]\n",
    "        if patient_id in result:\n",
    "            strain_type = result.split(' ')[1].split('_')[0]\n",
    "            print('this is strain_type', strain_type)\n",
    "            if strain_type not in strain_types:\n",
    "                strain_types.append(strain_type)\n",
    "            \n",
    "            print('this is strain_types list', strain_types)\n",
    "    if len(strain_types) >= 3:\n",
    "        patient_ids_with_all_strain_types.add(patient_id)\n",
    "\n",
    "print(patient_ids_with_all_strain_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf29f17-aa38-46d0-8385-9b44df2d14a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5b5f695-d5d0-47de-a014-614a253eaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_patients():\n",
    "    # Get list of all .tif files in the patient directory\n",
    "    image_files = glob(f'{patient_dir}/*.tif')\n",
    "\n",
    "    # Get all patient IDs\n",
    "    patient_ids = []\n",
    "    for image_file in image_files:\n",
    "        index = image_file.find(\"\\\\\")\n",
    "        result = image_file[index + 1:]\n",
    "        patient_ids.append(result.split('_')[0])\n",
    "\n",
    "    # Get all patient IDs with all 3 strain types\n",
    "    patient_ids_with_all_strain_types = set()\n",
    "    for patient_id in patient_ids:\n",
    "        strain_types = []\n",
    "        for image_file in image_files:\n",
    "            index = image_file.find(\"\\\\\")\n",
    "            result = image_file[index + 1:]\n",
    "            if patient_id in result:\n",
    "                strain_type = result.split('_')[1]\n",
    "                if strain_type not in strain_types:\n",
    "                    strain_types.append(strain_type)\n",
    "        print(strain_types)\n",
    "        if len(strain_types) >= 3:\n",
    "            patient_ids_with_all_strain_types.add(patient_id)\n",
    "\n",
    "    print(patient_ids_with_all_strain_types)\n",
    "\n",
    "    # Delete all patients without all 3 strain types\n",
    "    for patient_id in patient_ids:\n",
    "        if patient_id not in patient_ids_with_all_strain_types:\n",
    "            for image_file in image_files:\n",
    "                index = image_file.find(\"\\\\\")\n",
    "                result = image_file[index + 1:]\n",
    "                if patient_id in result:\n",
    "                    file_path = os.path.join(patient_dir, result)\n",
    "                    if os.path.exists(file_path):\n",
    "                        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aeb94a-1418-4733-a890-20b699d5d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_highest_res_image(files):\n",
    "    # Get the resolution of each image\n",
    "    resolutions = []\n",
    "    for file in files:\n",
    "        resolutions.append(os.path.getsize(file))\n",
    "    \n",
    "    # Get the index of the image with the highest resolution\n",
    "    max_res_index = resolutions.index(max(resolutions))\n",
    "\n",
    "    # Delete all images except the one with the highest resolution\n",
    "    for i in range(len(files)):\n",
    "        if i != max_res_index:\n",
    "            os.remove(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4d0bc6b-035b-4efc-b64c-f37148fff0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_highest_res():\n",
    "    # Get list of all .tif files in the patient directory\n",
    "    image_files = glob(f'{patient_dir}/*.tif')\n",
    "\n",
    "    # Get all patient IDs\n",
    "    patient_ids = []\n",
    "    for image_file in image_files:\n",
    "        index = image_file.find(\"\\\\\")\n",
    "        result = image_file[index + 1:]\n",
    "        patient_ids.append(result.split('_')[0])\n",
    "\n",
    "    # Get all patient IDs with all 3 strain types\n",
    "    patient_ids_with_all_strain_types_multiple_of_one = set()\n",
    "    patient_to_strains = dict()\n",
    "    for patient_id in patient_ids:\n",
    "        strain_types = []\n",
    "        for image_file in image_files:\n",
    "            index = image_file.find(\"\\\\\")\n",
    "            result = image_file[index + 1:]\n",
    "            if patient_id in result:\n",
    "                strain_type = result.split('_')[1]\n",
    "                if strain_type not in strain_types:\n",
    "                    strain_types.append(strain_type)\n",
    "        if len(strain_types) > 3:\n",
    "            patient_ids_with_all_strain_types_multiple_of_one.add(patient_id)\n",
    "        patient_to_strains[patient_id] = strain_types\n",
    "        \n",
    "\n",
    "    # For all strains with mutliples, keep the one with the highest resolution\n",
    "    for key in patient_to_strains.keys():\n",
    "        h_and_e_count, melan_count, sox10_count = 0, 0, 0\n",
    "        h_and_e_files, melan_files, sox10_files = [], [], []\n",
    "        for item in patient_to_strains[key]:\n",
    "            if 'h&e' in item:\n",
    "                h_and_e_count += 1\n",
    "                h_and_e_files.append(f'{patient_dir}\\\\' + key + \"_\" + item)\n",
    "            if 'melan' in item:\n",
    "                melan_count += 1\n",
    "                melan_files.append(f'{patient_dir}\\\\' + key + \"_\" + item)\n",
    "            if 'sox10' in item:\n",
    "                sox10_count += 1\n",
    "                sox10_files.append(f'{patient_dir}\\\\' + key + \"_\" + item)\n",
    "        if h_and_e_count > 1:\n",
    "            keep_highest_res_image(h_and_e_files)\n",
    "        if melan_count > 1:\n",
    "            keep_highest_res_image(melan_files)\n",
    "        if sox10_count > 1:\n",
    "            keep_highest_res_image(sox10_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55136973-6082-428e-9e4b-50235d6b6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up files by patient\n",
    "def split_files_by_patient():\n",
    "    # Get list of all .tif files in the patient directory\n",
    "    image_files = glob(f'{patient_dir}/*.tif')\n",
    "\n",
    "    patient_ids = set()\n",
    "    for image in image_files:\n",
    "        index = image.find(\"\\\\\")\n",
    "        result = image[index + 1:]\n",
    "        patient_ids.add(result.split('_')[0])\n",
    "\n",
    "    # Create a folder for each patient\n",
    "    for patient_id in patient_ids:\n",
    "        os.makedirs(os.path.join(patient_dir, patient_id), exist_ok = True)\n",
    "\n",
    "    # Move each image to the correct patient folder\n",
    "    for image_file in image_files:\n",
    "        index = image_file.find(\"\\\\\")\n",
    "        result = image_file[index + 1:]\n",
    "        patient_id = result.split('_')[0]\n",
    "        os.rename(image_file, f'{patient_dir}/{patient_id}/{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa0f630a-0ace-49dd-9c44-48ebe025a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files():\n",
    "    rename_files()\n",
    "    delete_patients()\n",
    "    keep_highest_res()\n",
    "    rename_files()\n",
    "    split_files_by_patient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a5116fe-f2ab-493f-826a-609469832710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/nhj4/Documents/STAT 390 Files/QuPath/processed_images\\\\h1915192 h&e_ROI_1.tif', 'C:/Users/nhj4/Documents/STAT 390 Files/QuPath/processed_images\\\\h1915192 melan a_ROI_1.tif', 'C:/Users/nhj4/Documents/STAT 390 Files/QuPath/processed_images\\\\h1915192 sox10_ROI_1.tif']\n",
      "['slice']\n",
      "['slice']\n",
      "['slice']\n",
      "set()\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "preprocess_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a64672-b090-482b-8df2-446db1da6ec6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Matching Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b16954-ea7b-4518-ba58-37e913f95d15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_unmatched(folder):\n",
    "    image_dict = defaultdict(list)\n",
    "\n",
    "    imgs = [cv2.imread(os.path.join(folder, img)) for img in os.listdir(folder)]\n",
    "\n",
    "    for img, name in zip(imgs, os.listdir(folder)):\n",
    "        stain = 'h&e' if 'h&e' in name.lower() else 'melan' if 'melan' in name.lower() else 'sox10'\n",
    "\n",
    "        image_dict[stain].append(img)\n",
    "\n",
    "    # reorder image sets such that h&e is first\n",
    "    return dict(sorted(image_dict.items()))\n",
    "\n",
    "\n",
    "def extract_main_contour(image):\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # adaptive threshold to handle variations in color intensity\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(blurred, 255,\n",
    "                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # apply morphological operations to clean up image\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    morph = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # find contours\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return the largest contour\n",
    "    return max(contours, key = cv2.contourArea)\n",
    "\n",
    "\n",
    "def distance(image1, image2):\n",
    "    # extract main contours\n",
    "    contour1 = extract_main_contour(image1)\n",
    "    contour2 = extract_main_contour(image2)\n",
    "\n",
    "    # calculate the area of both contours\n",
    "    area1 = cv2.contourArea(contour1)\n",
    "    area2 = cv2.contourArea(contour2)\n",
    "    \n",
    "    # calculate the area of the images\n",
    "    image1_area, image2_area = image1.shape[0] * image1.shape[1], image2.shape[0] * image2.shape[1]\n",
    "\n",
    "    # total area of contour\n",
    "    contour1_percentage, contour2_percentage = area1 / image1_area, area2 / image2_area\n",
    "\n",
    "    # if the contour area area aren't within 30% of each other, return maximum distance\n",
    "    if abs(contour1_percentage - contour2_percentage) > 0.3:\n",
    "        return np.inf\n",
    "    \n",
    "    # return distance score between the two contours\n",
    "    return cv2.matchShapes(contour1, contour2, cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "\n",
    "\n",
    "def distance_matrix(image_dict):\n",
    "    # set of images for each stain\n",
    "    set1, set2, set3 = image_dict.values()\n",
    "\n",
    "    # empty distance matrix to fill in\n",
    "    matrix = np.zeros((len(set1), len(set2), len(set3)))\n",
    "\n",
    "    # iterate through all possible 3-way matches\n",
    "    for (i, img1), (j, img2), (k, img3) in product(enumerate(set1), enumerate(set2), enumerate(set3)):\n",
    "        # compute distance score and fill in matrix\n",
    "        matrix[i, j, k] = distance(img1, img2) + distance(img2, img3) + distance(img1, img3)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def match(images, matches = None):\n",
    "    if not matches:\n",
    "        matches = []\n",
    "\n",
    "    # check if all stains have at least one image present\n",
    "    if any(len(imgs) == 0 for imgs in images.values()):\n",
    "        return matches\n",
    "\n",
    "    distances = distance_matrix(images)\n",
    "\n",
    "    min_idx = np.unravel_index(distances.argmin(), distances.shape)\n",
    "\n",
    "    matched_images = []\n",
    "\n",
    "    for stain, idx in zip(images.keys(), min_idx):\n",
    "        matched_images.append(images[stain][idx])\n",
    "\n",
    "        del images[stain][idx]\n",
    "\n",
    "    matches.append(matched_images)\n",
    "\n",
    "    # recursively call the function on the remaining images\n",
    "    return match(images, matches)\n",
    "\n",
    "\n",
    "def write_tif(img, path):\n",
    "    cv2.imwrite(path,\n",
    "                img,\n",
    "                [cv2.IMWRITE_TIFF_COMPRESSION,\n",
    "                 cv2.IMWRITE_TIFF_COMPRESSION_NONE])\n",
    "    \n",
    "\n",
    "def write_matched(matches, unmatched, patient):\n",
    "    base_dir = os.path.join('matches', patient)\n",
    "\n",
    "    os.makedirs(base_dir, exist_ok = True)\n",
    "\n",
    "    # iterate through 3-way matches\n",
    "    for i, match in enumerate(matches, 1):\n",
    "        match_dir = os.path.join(base_dir, f'match{i}')\n",
    "\n",
    "        os.makedirs(match_dir, exist_ok = True)\n",
    "\n",
    "        for j, slice in enumerate(match, 1):\n",
    "            write_tif(slice, os.path.join(match_dir, f'slice{j}.tif'))\n",
    "\n",
    "    # also save unmatched images\n",
    "    slices = list(chain.from_iterable(unmatched.values()))\n",
    "\n",
    "    if len(slices) > 0:\n",
    "        unmatched_dir = os.path.join(base_dir, 'unmatched')\n",
    "\n",
    "        os.makedirs(unmatched_dir, exist_ok = True)\n",
    "\n",
    "        for i, slice in enumerate(slices, 1):\n",
    "            write_tif(slice, os.path.join(unmatched_dir, f'slice{i}.tif'))\n",
    "                \n",
    "\n",
    "def match_pipeline(folder):\n",
    "    for patient in os.listdir(folder):\n",
    "        try:\n",
    "            image_dict = read_unmatched(os.path.join(folder, patient))\n",
    "\n",
    "            matches = match(image_dict)\n",
    "\n",
    "            write_matched(matches, image_dict, patient)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb251124-de0f-4296-946f-ce033e9dbe2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Rotation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a46519-3385-48d9-b42b-7a5a858b1b96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    contour = extract_main_contour(img)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    cv2.drawContours(mask, [contour], 0, (255, 255, 255), thickness = cv2.FILLED)\n",
    "    \n",
    "    intersected = cv2.bitwise_and(mask, img)\n",
    "\n",
    "    return intersected[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "def resize(img1, img2):\n",
    "    contour_areas = list(map(lambda x: cv2.contourArea(extract_main_contour(x)), [img1, img2]))\n",
    "\n",
    "    if contour_areas[0] < contour_areas[1]:\n",
    "        return cv2.resize(img1, img2.shape[1::-1]), img2\n",
    "    \n",
    "    return img1, cv2.resize(img2, img1.shape[1::-1])\n",
    "\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Calculate new dimensions after rotation\n",
    "    radians = np.deg2rad(angle)\n",
    "    new_w = int(abs(w * np.cos(radians)) + abs(h * np.sin(radians)))\n",
    "    new_h = int(abs(h * np.cos(radians)) + abs(w * np.sin(radians)))\n",
    "\n",
    "    # Update the rotation matrix for the new center and dimensions\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotation_matrix[0, 2] += (new_w - w) / 2\n",
    "    rotation_matrix[1, 2] += (new_h - h) / 2\n",
    "\n",
    "    return cv2.warpAffine(image, rotation_matrix, (new_w, new_h))\n",
    "\n",
    "\n",
    "def maximize_overlap(img1, img2, stepsize, angles = np.arange(0, 360, 90), cropped = False):\n",
    "    # crop the images to their ROIs if not already done\n",
    "    if not cropped:\n",
    "        img1 = crop(img1)\n",
    "\n",
    "    # calculate overlap score for each angle\n",
    "    scores = np.array([overlap_score(img1, img2, angle) for angle in angles])\n",
    "\n",
    "    # find angle that maximizes overlap score\n",
    "    best_angle = angles[np.argmax(scores)]\n",
    "\n",
    "    curr_stepsize = angles[1] - angles[0]\n",
    "\n",
    "    # base case\n",
    "    if curr_stepsize <= stepsize:\n",
    "        return best_angle\n",
    "\n",
    "    # zoom in on the best angle from the previous function call\n",
    "    new_angles = np.arange(best_angle - curr_stepsize, best_angle + curr_stepsize + 1, np.ceil(curr_stepsize/2))\n",
    "\n",
    "    # recursively call the function on the updated array of angles\n",
    "    return maximize_overlap(img1, img2, stepsize, new_angles, True)\n",
    "\n",
    "\n",
    "def check_dim(img1, img2, ratio):\n",
    "    img1_ratio = img1.shape[0]/img1.shape[1]\n",
    "    img2_ratio = img2.shape[0]/img2.shape[1]\n",
    "\n",
    "    img_ratios = [img1_ratio, img2_ratio]\n",
    "\n",
    "    if max(img_ratios)/min(img_ratios) > ratio:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def overlap_score(img1, img2, angle):\n",
    "    # rotate and crop image 1\n",
    "    img1 = crop(rotate_image(img1, angle))\n",
    "\n",
    "    # ensure that both dimensions of the rotated and reference images are within 50% of one another\n",
    "    if not check_dim(img1, img2, 1.5):\n",
    "        return 0\n",
    "    \n",
    "    # resize the images \n",
    "    img1, img2 = resize(img1, img2)\n",
    "\n",
    "    intersection = cv2.bitwise_and(img1, img2)\n",
    "    union = cv2.bitwise_or(img1, img2)\n",
    "    \n",
    "    return np.sum(intersection) / np.sum(union)\n",
    "\n",
    "\n",
    "def rotate(img1, img2, stepsize = 1, optimize = True):\n",
    "    if optimize:\n",
    "        best_angle = maximize_overlap(img2, img1, stepsize)\n",
    "    else:\n",
    "        best_angle = maximize_overlap(img2, img1, stepsize, np.arange(0, 360 + stepsize, stepsize))\n",
    "\n",
    "    return crop(rotate_image(crop(img2), best_angle))\n",
    "\n",
    "\n",
    "def align_images(imgs, stepsize = 1):\n",
    "    img1, img2, img3 = imgs\n",
    "\n",
    "    img1 = crop(img1)\n",
    "\n",
    "    # align the images with respect to the h&e image (img1)\n",
    "    img2 = rotate(img1, img2, stepsize)\n",
    "    img3 = rotate(img1, img3, stepsize)\n",
    "\n",
    "    if not check_dim(img1, img2, 1.15):\n",
    "        img2 = rotate(img1, img2, stepsize, False)\n",
    "\n",
    "    if not check_dim(img1, img3, 1.15):\n",
    "        img3 = rotate(img1, img3, stepsize, False)\n",
    "    \n",
    "    return img1, img2, img3\n",
    "\n",
    "\n",
    "def read(dir):\n",
    "    return [cv2.imread(os.path.join(dir, slice)) for slice in os.listdir(dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499db243-25e9-43bd-8531-9e5333815827",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Epithelium Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e859998-cc18-4a5d-8ad7-58214f74b89e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_epithelium(img, output_dir):\n",
    "    # Convert the image to RGB and YCrCb\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_ycrcb = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2YCrCb)\n",
    "    \n",
    "    # Binning the luminance (Y) channel\n",
    "    lumma_bins_n = 20\n",
    "    divisor = np.floor(255 / lumma_bins_n).astype(np.uint8)\n",
    "    lumma_binned = np.floor(img_ycrcb[:, :, 0] / divisor).astype(np.uint8)\n",
    "    \n",
    "    # Find the most common luminance bin\n",
    "    most_pixels_bin = -1\n",
    "    most_pixels = 0\n",
    "    for bin_i in range(0, lumma_bins_n + 1):\n",
    "        n_pixels = np.count_nonzero(lumma_binned == bin_i)\n",
    "        if n_pixels > most_pixels:\n",
    "            most_pixels = n_pixels\n",
    "            most_pixels_bin = bin_i\n",
    "\n",
    "    background_bin = most_pixels_bin\n",
    "    background = lumma_binned == background_bin\n",
    "    background = morphology.remove_small_objects(background, 5000)\n",
    "    background = morphology.remove_small_holes(background, 10000)\n",
    "\n",
    "    # Binning the Cr (Red Chroma) channel\n",
    "    Cr_bins_n = 50\n",
    "    divisor = np.floor(255 / Cr_bins_n).astype(np.uint8)\n",
    "    Cr_binned = np.floor(img_ycrcb[:, :, 2] / divisor).astype(np.uint8)\n",
    "    \n",
    "    # Find the most common Cr bin\n",
    "    most_pixels_bin = -1\n",
    "    most_pixels = 0\n",
    "    for bin_i in range(0, Cr_bins_n + 1):\n",
    "        n_pixels = np.count_nonzero(Cr_binned == bin_i)\n",
    "        if n_pixels > most_pixels:\n",
    "            most_pixels = n_pixels\n",
    "            most_pixels_bin = bin_i\n",
    "\n",
    "    # Stroma mask generation\n",
    "    stroma_bin = most_pixels_bin\n",
    "    stroma = Cr_binned == stroma_bin\n",
    "    stroma = stroma + (Cr_binned == stroma_bin - 1)\n",
    "    stroma = stroma + (Cr_binned == stroma_bin - 2)\n",
    "    stroma = stroma * np.invert(background)\n",
    "    stroma = morphology.dilation(stroma, morphology.square(3))\n",
    "    stroma = morphology.remove_small_objects(stroma, 1000)\n",
    "\n",
    "    # Epithelia mask generation\n",
    "    epithelia_bin = stroma_bin + 2\n",
    "    epithelia = Cr_binned == epithelia_bin\n",
    "    epithelia = epithelia + (Cr_binned == epithelia_bin + 1)\n",
    "    epithelia = epithelia + (Cr_binned == epithelia_bin + 2)\n",
    "    epithelia = epithelia + (Cr_binned == epithelia_bin + 3)\n",
    "    epithelia = epithelia + (Cr_binned == epithelia_bin + 4)\n",
    "    epithelia = epithelia * np.invert(background)\n",
    "    epithelia = epithelia * np.invert(stroma)\n",
    "    epithelia = epithelia * np.invert(img_ycrcb[:, :, 1] < 120)\n",
    "    epithelia = morphology.dilation(epithelia, morphology.square(2))\n",
    "    epithelia = morphology.remove_small_objects(epithelia, 500)\n",
    "    epithelia = morphology.remove_small_holes(epithelia, 10000)\n",
    "\n",
    "    # Adjust stroma to only show areas not covered by epithelia\n",
    "    stroma_only = stroma * np.invert(epithelia)  \n",
    "\n",
    "    # Apply the masks to the original image \n",
    "    epithelia_img = cv2.bitwise_and(img_rgb, img_rgb, mask=(epithelia.astype(np.uint8) * 255))\n",
    "    stroma_img = cv2.bitwise_and(img_rgb, img_rgb, mask=(stroma_only.astype(np.uint8) * 255))\n",
    "\n",
    "    # Combine both epithelia and stroma images\n",
    "    combined_img = cv2.add(epithelia_img, stroma_img)\n",
    "\n",
    "    #################################\n",
    "    if output_dir == 'output_dir':\n",
    "        return epithelia_img, stroma_img, combined_img\n",
    "    #################################\n",
    "\n",
    "    # Save the combined image\n",
    "    combined_filename = os.path.join(output_dir, \"epithelia_and_stroma_combined.tif\")\n",
    "    cv2.imwrite(combined_filename, cv2.cvtColor(combined_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Save the individual epithelium and stroma images if desired\n",
    "    epithelia_filename = os.path.join(output_dir, \"epithelia.tif\")\n",
    "    cv2.imwrite(epithelia_filename, cv2.cvtColor(epithelia_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    stroma_filename = os.path.join(output_dir, \"stroma.tif\")\n",
    "    cv2.imwrite(stroma_filename, cv2.cvtColor(stroma_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "def write(imgs, patient, match_name):\n",
    "    output_dir = os.path.join('matches', patient, match_name)\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        # Save the aligned images\n",
    "        write_tif(img, os.path.join(output_dir, f'slice{i}.tif'))\n",
    "\n",
    "        # Only apply extract_epithelium on slice1 \n",
    "        if i == 1:\n",
    "            extract_epithelium(img, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864383d-5dc1-4eab-af25-47eebb5ba37a",
   "metadata": {},
   "source": [
    "# Patching Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c5b1c7d-3b16-48a9-bd31-385194999e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(he_image, patch_width, patch_height):\n",
    "    output_dir = 'output_dir' #not needed, but used in extract_epithelium function, so I modified it a little\n",
    "\n",
    "    # xtract the epithelium and stroma images\n",
    "    epithelia_img, stroma_img, combined_img = extract_epithelium(he_image, output_dir)\n",
    "        \n",
    "    # Convert to grayscale and binarize the combined image\n",
    "    gray = cv2.cvtColor(combined_img, cv2.COLOR_BGR2GRAY)\n",
    "    binary = np.array(gray) > 0  # Non-black areas become True\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(he_image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "    # Skeletonize the shape to get the centerline\n",
    "    skeleton = morphology.skeletonize(binary)\n",
    "        \n",
    "    # Find the coordinates of skeleton pixels\n",
    "    y, x = np.where(skeleton)\n",
    "    skeleton_coords = list(zip(x, y))[::100]\n",
    "        \n",
    "    # Calculate gradients at each skeleton point to determine the tangent direction\n",
    "    patches = []\n",
    "    coords = []\n",
    "    for i, (x, y) in enumerate(skeleton_coords[:-1]):\n",
    "        # Compute approximate direction to next skeleton point (dx, dy)\n",
    "        dx = skeleton_coords[i + 1][0] - x\n",
    "        dy = skeleton_coords[i + 1][1] - y\n",
    "        length = np.sqrt(dx**2 + dy**2)\n",
    "        if length == 0:\n",
    "            continue  # Skip if there's no movement\n",
    "            \n",
    "        # Normalize direction to get unit vector\n",
    "        dx /= length\n",
    "        dy /= length\n",
    "            \n",
    "        # Compute perpendicular vector for the patch orientation\n",
    "        perp_dx = -dy\n",
    "        perp_dy = dx\n",
    "            \n",
    "        # Calculate corner points of the patch rectangle\n",
    "        half_width = patch_width // 2\n",
    "        half_height = patch_height // 2\n",
    "        corners = [\n",
    "            (x + perp_dx * half_width, y + perp_dy * half_height),\n",
    "            (x - perp_dx * half_width, y - perp_dy * half_height),\n",
    "            (x + perp_dx * half_width + dx * patch_height, y + perp_dy * half_height + dy * patch_height),\n",
    "            (x - perp_dx * half_width + dx * patch_height, y - perp_dy * half_height + dy * patch_height),\n",
    "        ]\n",
    "            \n",
    "        # Crop the patch from the image using the bounding box of the rotated rectangle\n",
    "        min_x = int(min(c[0] for c in corners))\n",
    "        max_x = int(max(c[0] for c in corners))\n",
    "        min_y = int(min(c[1] for c in corners))\n",
    "        max_y = int(max(c[1] for c in corners))\n",
    "        patch = image_pil.crop((min_x, min_y, max_x, max_y))\n",
    "            \n",
    "        # Check if the patch contains parts from the stroma and epithelium image\n",
    "        patch_stroma = stroma_img[min_y:max_y, min_x:max_x]\n",
    "        patch_epithelia = epithelia_img[min_y:max_y, min_x:max_x]\n",
    "        \n",
    "        # Check if patch contains both stroma and epithelia\n",
    "        patch_np = np.array(patch)\n",
    "        if np.any(patch_stroma > 0) and np.any(patch_epithelia > 0):\n",
    "            # Check if the patch has between 10-70% black pixels - this is approximately the range we want\n",
    "            black_pixels = np.sum(np.all(patch_np == [0, 0, 0], axis=-1))\n",
    "            total_pixels = patch_np.shape[0] * patch_np.shape[1]\n",
    "            if black_pixels / total_pixels > 0.1 and black_pixels / total_pixels < 0.7:\n",
    "                patches.append(patch)\n",
    "                coords.append((min_x, min_y, max_x, max_y))\n",
    "\n",
    "    # Check for overlapping patches and remove them\n",
    "    non_overlapping_patches = []\n",
    "    non_overlapping_coords = []\n",
    "    for i, coord1 in enumerate(coords):\n",
    "        overlap = False\n",
    "        for j, coord2 in enumerate(non_overlapping_coords):\n",
    "            if not (coord1[2] < coord2[0] or coord1[0] > coord2[2] or coord1[3] < coord2[1] or coord1[1] > coord2[3]):\n",
    "                overlap = True\n",
    "                break\n",
    "        if not overlap:\n",
    "            non_overlapping_patches.append(patches[i])\n",
    "            non_overlapping_coords.append(coord1)\n",
    "    patches = non_overlapping_patches\n",
    "    coords = non_overlapping_coords\n",
    "\n",
    "    return patches, coords\n",
    "\n",
    "\n",
    "def normalize_coords(ref_image, new_image, coords):\n",
    "    ref_y, ref_x = ref_image.shape[:2]\n",
    "    new_y, new_x = new_image.shape[:2]\n",
    "\n",
    "    xmin_norm = int(coords[0]/ref_x * new_x)\n",
    "    ymin_norm = int(coords[1]/ref_y * new_y)\n",
    "\n",
    "    xmax_norm = int(coords[2]/ref_x * new_x)\n",
    "    ymax_norm = int(coords[3]/ref_y * new_y)\n",
    "\n",
    "    return xmin_norm, ymin_norm, xmax_norm, ymax_norm\n",
    "\n",
    "\n",
    "def get_patches_across_stains(patches, coords, image1, image2, image3):\n",
    "    # Check the same region across all stains\n",
    "    patches_across_stains = []\n",
    "    coords_across_stains = []\n",
    "\n",
    "    for i, patch in enumerate(patches):\n",
    "        min_x, min_y, max_x, max_y = coords[i]\n",
    "\n",
    "        x_dim = max_x - min_x\n",
    "        y_dim = max_y - min_y\n",
    "\n",
    "        patch_across_stains = []\n",
    "        coord_across_stains = []\n",
    "\n",
    "        patch_across_stains.append(image1[min_y:max_y, min_x:max_x])\n",
    "        coord_across_stains.append(coords[i])\n",
    "\n",
    "        coords_norm2 = normalize_coords(image1, image2, coords[i])\n",
    "        coord_across_stains.append(coords_norm2)\n",
    "\n",
    "        xmin_norm2, ymin_norm2, xmax_norm2, ymax_norm2 = coords_norm2\n",
    "        patch2_norm = image2[ymin_norm2:ymax_norm2, xmin_norm2:xmax_norm2]\n",
    "        patch_across_stains.append(cv2.resize(patch2_norm, (x_dim, y_dim)))\n",
    "\n",
    "        coords_norm3 = normalize_coords(image1, image3, coords[i])\n",
    "        coord_across_stains.append(coords_norm3)\n",
    "\n",
    "        xmin_norm3, ymin_norm3, xmax_norm3, ymax_norm3 = coords_norm3\n",
    "        patch3_norm = image3[ymin_norm3:ymax_norm3, xmin_norm3:xmax_norm3]\n",
    "        patch_across_stains.append(cv2.resize(patch3_norm, (x_dim, y_dim)))\n",
    "\n",
    "        # Check if the patch contains parts from all three images\n",
    "        if all(np.any(patch > 0) for patch in patch_across_stains):\n",
    "            # Check if the patch has between 5-80% black pixels - this is approximately the range we want\n",
    "            black_pixels = [np.sum(np.all(patch == [0, 0, 0], axis=-1)) for patch in patch_across_stains]\n",
    "            total_pixels = patch_across_stains[0].shape[0] * patch_across_stains[0].shape[1]\n",
    "            black_pixel_percentages = [black_pixel / total_pixels for black_pixel in black_pixels]\n",
    "\n",
    "            if all(0.05 <= percentage <= 0.8 for percentage in black_pixel_percentages):\n",
    "                patches_across_stains.append(patch_across_stains)\n",
    "                coords_across_stains.append(coord_across_stains)\n",
    "\n",
    "    return patches_across_stains, coords_across_stains\n",
    "\n",
    "\n",
    "def write_pc(patches, coords, imgs, patient, match):\n",
    "    # save extracted patches\n",
    "    output_dir = os.path.join('patches', patient, match)\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "    for i, patch_set in enumerate(patches, 1):\n",
    "        patch_dir = os.path.join(output_dir, f'patch{i}')\n",
    "\n",
    "        os.makedirs(patch_dir, exist_ok = True)\n",
    "\n",
    "        for j, patch in enumerate(patch_set, 1):\n",
    "            write_tif(patch, os.path.join(patch_dir, f'stain{j}.tif'))\n",
    "\n",
    "\n",
    "def rotate_extract_patch(match_dir):\n",
    "    for patient in os.listdir(match_dir):\n",
    "        for match in os.listdir(os.path.join(match_dir, patient)):\n",
    "            if match.startswith('match'):\n",
    "                imgs = read(os.path.join(match_dir, patient, match))\n",
    "\n",
    "                aligned_images = align_images(imgs)\n",
    "\n",
    "                write(aligned_images, patient, match)\n",
    "\n",
    "                a1, a2, a3 = aligned_images\n",
    "\n",
    "                # Extract patches from the aligned images\n",
    "                patches, coords = extract_patches(a1, patch_width = 300, patch_height = 300)\n",
    "\n",
    "                # Get patches across stains\n",
    "                patches_across_stains, coords_across_stains = get_patches_across_stains(patches, coords, a1, a2, a3)\n",
    "\n",
    "                # Save the patches\n",
    "                write_pc(patches_across_stains, coords_across_stains, aligned_images, patient, match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c8fb8-39fb-4bcd-a0fb-c1894ea2b123",
   "metadata": {},
   "source": [
    "# Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da0ff779-53bc-4ece-ac12-573bc5c16f6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patient_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpreprocess_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m match_pipeline(patient_dir)\n\u001b[0;32m      3\u001b[0m rotate_extract_patch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 133\u001b[0m, in \u001b[0;36mpreprocess_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_files\u001b[39m():\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mrename_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     delete_patients()\n\u001b[0;32m    137\u001b[0m     keep_highest_res()\n",
      "Cell \u001b[1;32mIn[14], line 102\u001b[0m, in \u001b[0;36mrename_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename_files\u001b[39m():\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Get list of all .tif files in the patient directory\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     image_files \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Replace ROI with slice\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'patient_dir' is not defined"
     ]
    }
   ],
   "source": [
    "preprocess_files()\n",
    "match_pipeline(patient_dir)\n",
    "rotate_extract_patch('matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53e5f2-a734-4017-9886-706f2876a686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
